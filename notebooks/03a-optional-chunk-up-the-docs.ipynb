{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9bd458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78089f5d-bde1-4fe3-8498-b5c871c7093a",
   "metadata": {},
   "source": [
    "# Chunk up the Docs and Index them in Vertex Matching Engine \n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/language/referencearchitectures/setup.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/referencearchitectures/setup.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/blob/main/language/referencearchitectures/setup.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee50022-9d4a-48f1-8c1e-3cd02a91943e",
   "metadata": {},
   "source": [
    "## Overview\n",
    "This notebook has been marked as optional as it's providing an example of how you can work with other forms of unstructured data sources in different formats and also insert those into your Vector Store DB, but is not required to execute the remaining notebooks in this repo. \n",
    "\n",
    "Here we cover how to use [LangChain and Vertex AI](https://python.langchain.com/en/latest/modules/models/text_embedding/examples/google_vertex_ai_palm.html) to extract text embeddings from a variety of source document types, and index them with Vertex Matching Engine. From each document source (see below), various metadata fields will be retained and saved to the original text's GCS blob metadata. For a comprehenive review of using LangChain with Vertex AI, see [intro_langchain_palm_api.ipynb](https://github.com/GoogleCloudPlatform/generative-ai/blob/dev/language/examples/langchain/intro_langchain_palm_api.ipynb)\n",
    "\n",
    "**Source sample document types included in this notebook:**\n",
    "* BigQuery Tables\n",
    "* PDF\n",
    "* Word docs\n",
    "* PowerPoint\n",
    "* YouTube videos\n",
    "\n",
    "**Throughout this notebook we will index documents with `add_texts()`**\n",
    "\n",
    "* This class method assigns a unique ID (UUID) to each source chunk\n",
    "* The original text chunk is uploaded to GCS, where the metadata are stored in the GCS blob metadata fields, and the blob name is equal to the UUID\n",
    "* The associated embedding vector is indexed (via stream update) in Vertex AI Matching Engine using the same UUID  \n",
    "\n",
    "<center>\n",
    "<img src=\"imgs/langchain_intro.png\" width=\"800\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b751d533-e12d-4669-9ab2-30d5221146cb",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "\n",
    "This notebook will show how to apply the following transfomations for each document source:\n",
    "* Chunk the text to sizes that can be indexed using the embeddings model\n",
    "* Upload the original text + metadata to Google Cloud Storage (GCS)\n",
    "* Extract embedding representation of text chunk using the Vertex PaLM API\n",
    "* Stream update embedding vector representation to Vertex AI Matching Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea82ab6-9f6e-44c9-acb4-92b5ba60a4e7",
   "metadata": {},
   "source": [
    "### Costs\n",
    "This tutorial uses billable components of Google Cloud:\n",
    "\n",
    "* Vertex AI Generative AI Studio\n",
    "* Vertex AI Matching Engine\n",
    "* BigQuery Storage & BigQuery Compute\n",
    "* Google Cloud Storage\n",
    "\n",
    "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing),\n",
    "and use the [Pricing Calculator](https://cloud.google.com/products/calculator/)\n",
    "to generate a cost estimate based on your projected usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0d3d5e-0958-4876-a117-df67cc8deb09",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "**Colab only:** Uncomment the following cell to restart the kernel. For Vertex AI Workbench you can restart the terminal using the button on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2576ee8e-2815-4a52-94db-407063bdae13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Automatically restart kernel after installs so that your environment can access the new packages\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696e1e5b-b078-4772-976e-1cd3b41aa66f",
   "metadata": {},
   "source": [
    "### Authenticating your notebook environment\n",
    "* If you are using **Colab** to run this notebook, uncomment the cell below and continue.\n",
    "* If you are using **Vertex AI Workbench**, check out the setup instructions [here](https://github.com/GoogleCloudPlatform/generative-ai/tree/main/setup-env)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f427c36-5a12-498e-bf8c-e7d644b852dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5051ee4e-9565-4bbe-aeaf-72393bc8524e",
   "metadata": {},
   "source": [
    "### Make sure you edit the values below\n",
    "Each time you run the notebook for the first time with new variables, you just need to edit the actor prefix and version variables below. They are needed to grab all the other variables in the notebook configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ddffc08-76e8-4214-8917-c7d5caf04554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTOR_PREFIX       : ggl\n",
      "VERSION            : v1\n"
     ]
    }
   ],
   "source": [
    "# CREATE_NEW_ASSETS        = True # True | False\n",
    "ACTOR_PREFIX             = \"ggl\"\n",
    "VERSION                  = 'v1'\n",
    "\n",
    "# print(f\"CREATE_NEW_ASSETS  : {CREATE_NEW_ASSETS}\")\n",
    "print(f\"ACTOR_PREFIX       : {ACTOR_PREFIX}\")\n",
    "print(f\"VERSION            : {VERSION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2173d32-c59b-4d17-8827-71fdd1929324",
   "metadata": {},
   "source": [
    "### Load configuration settings from setup notebook\n",
    "> Set the constants used in this notebook and load the config settings from the `00-env-setup.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fa8116d-d96a-4bd4-921c-3c631e11bdc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUCKET_NAME        : zghost-ggl-v1\n",
      "BUCKET_URI         : gs://zghost-ggl-v1\n",
      "\n",
      "PROJECT_ID               = \"cpg-cdp\"\n",
      "PROJECT_NUM              = \"939655404703\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"genai-haystack-vpc\"\n",
      "\n",
      "CREATE_NEW_ASSETS        = \"True\"\n",
      "ACTOR_PREFIX             = \"ggl\"\n",
      "VERSION                  = \"v1\"\n",
      "ACTOR_NAME               = \"google\"\n",
      "ACTOR_CATEGORY           = \"cyber security\"\n",
      "\n",
      "BUCKET_NAME              = \"zghost-ggl-v1\"\n",
      "EMBEDDING_DIR_BUCKET     = \"zghost-ggl-v1-emd-dir\"\n",
      "\n",
      "BUCKET_URI               = \"gs://zghost-ggl-v1\"\n",
      "EMBEDDING_DIR_BUCKET_URI = \"gs://zghost-ggl-v1-emd-dir\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/939655404703/global/networks/genai-haystack-vpc\"\n",
      "\n",
      "ME_INDEX_NAME            = \"vectorstore_ggl_v1\"\n",
      "ME_INDEX_ENDPOINT_NAME   = \"vectorstore_ggl_v1_endpoint\"\n",
      "ME_DIMENSIONS            = \"768\"\n",
      "\n",
      "MY_BQ_DATASET            = \"zghost_ggl_v1\"\n",
      "MY_BQ_TRENDS_DATASET     = \"zghost_ggl_v1_trends\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "BUCKET_NAME              = f'zghost-{ACTOR_PREFIX}-{VERSION}'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "print(f\"BUCKET_NAME        : {BUCKET_NAME}\")\n",
    "print(f\"BUCKET_URI         : {BUCKET_URI}\")\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19aa620b-b6e4-4240-bf7c-92ff0001788e",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "780b0288-27ea-4dcb-880c-72c675d147b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"..\")\n",
    "from zeitghost.gdelt.GdeltData import GdeltData\n",
    "from zeitghost.bigquery.BigQueryAccessor import BigQueryAccessor\n",
    "\n",
    "from zeitghost.agents.LangchainAgent import LangchainAgent\n",
    "from zeitghost.vertex.LLM import VertexLLM\n",
    "\n",
    "from zeitghost.vertex.MatchingEngineCRUD import MatchingEngineCRUD\n",
    "from zeitghost.vertex.MatchingEngineVectorstore import MatchingEngineVectorStore\n",
    "\n",
    "from zeitghost.vertex.Embeddings import VertexEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a63f2ab-b20d-4ee1-b6fb-060ed839fd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform as vertex_ai\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "\n",
    "from langchain.document_loaders import DataFrameLoader\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.document_loaders import BigQueryLoader\n",
    "\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import io\n",
    "\n",
    "from IPython.display import display, Image, Markdown\n",
    "from PIL import Image, ImageDraw\n",
    "import logging\n",
    "logging.basicConfig(level = logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d87cae-3826-4b35-8105-abbe757eeb82",
   "metadata": {},
   "source": [
    "Instantiate Google Cloud SDK clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afd812ef-6789-4459-a27b-fdcd88bf5f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "vertex_ai.init(project=PROJECT_ID,location=LOCATION)\n",
    "\n",
    "# bigquery client\n",
    "bqclient = bigquery.Client(\n",
    "    project=PROJECT_ID,\n",
    "    # location=LOCATION\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ec1363-7ace-40e2-af75-e26b27cce6e7",
   "metadata": {},
   "source": [
    "Helper function for inspecting blob data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a00dce8-c2b3-4a45-b292-6a5198e14d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_gcs_blob_metadata(blob_name, bucket_name):\n",
    "    \"\"\"\n",
    "    inspect blobs uploaded to GCS\n",
    "    \"\"\"\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.get_blob(blob_name)\n",
    "    print(f\"Metadata: {blob.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5fd9ee-083d-4782-b70c-7f194211d458",
   "metadata": {},
   "source": [
    "## Initialize Vertex AI Matching Engine & GenAI Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37becca6-7d1f-4f2d-992d-e9a1c9e85f00",
   "metadata": {},
   "source": [
    "### Matching Engine Index and IndexEndpoint\n",
    "Initialize the Vertex AI Matching Engine resources. You should have already created these resources in the [Setup Vertex Vector Store]() notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f06e654e-c554-4bad-8953-3ae076820a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mengine = MatchingEngineCRUD(\n",
    "    project_id=PROJECT_ID \n",
    "    , project_num=PROJECT_NUM\n",
    "    , region=LOCATION \n",
    "    , index_name=ME_INDEX_NAME\n",
    "    , vpc_network_name=VPC_NETWORK_FULL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "956e97ed-e725-462a-9e10-6458261a07e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ME_INDEX_RESOURCE_NAME  = projects/939655404703/locations/us-central1/indexes/5031884178191286272\n",
      "ME_INDEX_ENDPOINT_ID    = projects/939655404703/locations/us-central1/indexEndpoints/3175838181761220608\n",
      "ME_INDEX_ID             = 5031884178191286272\n"
     ]
    }
   ],
   "source": [
    "ME_INDEX_RESOURCE_NAME, ME_INDEX_ENDPOINT_ID = mengine.get_index_and_endpoint()\n",
    "ME_INDEX_ID=ME_INDEX_RESOURCE_NAME.split(\"/\")[5]\n",
    "\n",
    "print(f\"ME_INDEX_RESOURCE_NAME  = {ME_INDEX_RESOURCE_NAME}\")\n",
    "print(f\"ME_INDEX_ENDPOINT_ID    = {ME_INDEX_ENDPOINT_ID}\")\n",
    "print(f\"ME_INDEX_ID             = {ME_INDEX_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183ef1ce-96df-45c5-ade8-7444a09f148b",
   "metadata": {},
   "source": [
    "### Vertex AI LLM & Embeddings Generator\n",
    "\n",
    "Instantiate the Vertex AI LLMs using the helper classes, with different parameters passed to be used for different scenarios\n",
    "\n",
    "For more information on parameters such as temperature, top_p, top_k, see [Getting Started with the Vertex AI PaLM API & Python SDK](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/intro_palm_api.ipynb)\n",
    "\n",
    "*  `stop=None`: in this case, we are NOT passing a stopword when calling the LLM\n",
    "* `stop=['Observation:']`: in this case, we are stopping when the LLM response shows <i>Observation:</i> to avoid hallucinations from the BigQuery and Pandas agents\n",
    "* `strip=True`: we've noticed that when working with PaLM + BigQuery Langchain Agents, enabling string parsing stripping capabilities can prevent hallucinations \n",
    "\n",
    "To read more about different types of agents, see the [Langchain Documentation on Agents](https://python.langchain.com/en/latest/modules/agents.html)\n",
    "\n",
    "Make sure your REQUESTS_PER_MINUTE does not exceed your project quota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e51aa3d-5bc2-4e0b-83f7-1225b86d7047",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = VertexLLM(\n",
    "    temperature=0\n",
    "    , stop=['Observation:']\n",
    "    # , stop=None\n",
    "    , strip=True\n",
    "    , strip_chars=['\\\\', '\\\\\\\\']\n",
    "    , max_output_tokens=1000\n",
    "    , top_p=0.7\n",
    "    , top_k=40\n",
    ")\n",
    "\n",
    "REQUESTS_PER_MINUTE = 299 # project quota==300\n",
    "vertex_embedding = VertexEmbeddings(requests_per_minute=REQUESTS_PER_MINUTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfc9f75-8f92-4901-865a-6336d2a04e8c",
   "metadata": {},
   "source": [
    "Let's ping the LLM and verify we are getting a response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a3d6d78-245d-4fb5-bbc9-862199574dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Widespread Panic is an American rock band formed in Athens, Georgia, in 1986. The band\\'s lineup consists of John Bell (vocals, guitar), Jimmy Herring (guitar, vocals), Dave Schools (bass), John \"JoJo\" Hermann (keyboards), and Duane Trucks (drums). Widespread Panic has released 15 studio albums, four live albums, and two compilation albums.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm('In no more than 50 words, what can you tell me about the band Widespread Panic?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462994a3-2e30-42fd-9888-9569e469d149",
   "metadata": {},
   "source": [
    "### Initialize Matching Engine VectorStore\n",
    "In this notebook we will import the MatchingEngineVector class which will:\n",
    "- Enable streaming index updates to a Matching Engine Index\n",
    "- While the embeddings are stored in the Matching Engine, the embedded documents will be stored in GCS.     \n",
    "    - An existing Index and corresponding Endpoint are preconditions for\n",
    "    using this module.\n",
    "    - See usage in docs/modules/indexes/vectorstores/examples/matchingengine.ipynb\n",
    "    - Note that this implementation is mostly meant for reading if you are\n",
    "    planning to do a real time implementation. While reading is a real time\n",
    "    operation, updating the index takes close to one hour.\n",
    "- Note: at current time of writing, creating ME index from LangChain only supports batch index updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6942ca6f-3c2b-4a48-956a-853b7d3ce852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize vector store\n",
    "me = MatchingEngineVectorStore.from_components(\n",
    "    project_id=PROJECT_ID\n",
    "    , region=LOCATION\n",
    "    , gcs_bucket_name=EMBEDDING_DIR_BUCKET_URI\n",
    "    , embedding=vertex_embedding\n",
    "    , index_id=ME_INDEX_ID\n",
    "    , endpoint_id=ME_INDEX_ENDPOINT_ID\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f183fc-041c-40d0-9b2b-3ff1902ef35d",
   "metadata": {},
   "source": [
    "## BigQuery Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573d5bda-c640-4410-81c3-ac080925410d",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"imgs/chunk_bq_tables_flow.png\" width=\"750\"/>\n",
    "</center>\n",
    "\n",
    "When chunking BigQuery tables, we specify the columns we want to chunk, and the columns we want to include as metadata\n",
    "\n",
    "the `me.chunk_bq_table()` method returns a LangChain Document type consisting of `page_content` (the chunked text) and `metadata` (data describing attributes of page content):\n",
    "\n",
    "```python\n",
    "from langchain.schema import Document\n",
    "\n",
    "Document(\n",
    "    page_content=\"This is my document. It is full of text that I've gathered from other places\",\n",
    "    metadata={\n",
    "        \"my_document_id\": 234234,\n",
    "        \"my_document_source\": \"The LangChain Papers\",\n",
    "        \"my_document_create_time\": 1680013019,\n",
    "    },\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2df982a-1553-4846-8bfe-d81caa200ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>url</th>\n",
       "      <th>language</th>\n",
       "      <th>date</th>\n",
       "      <th>Actor1Name</th>\n",
       "      <th>Actor2Name</th>\n",
       "      <th>GoldsteinScale</th>\n",
       "      <th>NumSources</th>\n",
       "      <th>NumArticles</th>\n",
       "      <th>AvgTone</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google Search agrees to pay $23 million settle...</td>\n",
       "      <td>People who searched using Google and clicked o...</td>\n",
       "      <td>People who searched using Google and clicked o...</td>\n",
       "      <td>2023-06-13 00:00:00+00:00</td>\n",
       "      <td>https://www.cincinnati.com/story/money/2023/06...</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://www.cincinnati.com/story/money/2023/06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zib Digital Explains How Google Search Ads Wil...</td>\n",
       "      <td>Zib Digital Explains How Google Search Ads Wil...</td>\n",
       "      <td>Zib Digital Explains How Google Search Ads Wil...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>http://www.itnewsonline.com/news/Zib-Digital-E...</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>http://www.itnewsonline.com/news/Zib-Digital-E...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Google Search agrees to pay $23 million settle...   \n",
       "1  Zib Digital Explains How Google Search Ads Wil...   \n",
       "\n",
       "                                                text  \\\n",
       "0  People who searched using Google and clicked o...   \n",
       "1  Zib Digital Explains How Google Search Ads Wil...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  People who searched using Google and clicked o...   \n",
       "1  Zib Digital Explains How Google Search Ads Wil...   \n",
       "\n",
       "               publish_date  \\\n",
       "0 2023-06-13 00:00:00+00:00   \n",
       "1                       NaT   \n",
       "\n",
       "                                                 url language date Actor1Name  \\\n",
       "0  https://www.cincinnati.com/story/money/2023/06...       en                   \n",
       "1  http://www.itnewsonline.com/news/Zib-Digital-E...       en                   \n",
       "\n",
       "  Actor2Name GoldsteinScale  NumSources  NumArticles  AvgTone  \\\n",
       "0                                     0            0      0.0   \n",
       "1                                     0            0      0.0   \n",
       "\n",
       "                                              source  \n",
       "0  https://www.cincinnati.com/story/money/2023/06...  \n",
       "1  http://www.itnewsonline.com/news/Zib-Digital-E...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TABLE_NAME = f'scraped_test_geg_articles_{ACTOR_PREFIX}_{VERSION}'\n",
    "TABLE_REF  = f'{PROJECT_ID}.{MY_BQ_DATASET}.{TABLE_NAME}'\n",
    "\n",
    "query = f\"\"\"\n",
    "    SELECT * \n",
    "    FROM `{TABLE_REF}`\n",
    "\"\"\"\n",
    "df = bqclient.query(query).to_dataframe().head(2)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2ac39d-3668-4586-9302-c46732338e3b",
   "metadata": {},
   "source": [
    "Now, let's define the metadata columns that we want to retain - keeping in mind what may be useful for a conversational agent to be able use to answer questions on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "075ee1dd-5fcb-49d3-a2d7-ef4618ed493e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['title',\n",
       " 'summary',\n",
       " 'publish_date',\n",
       " 'url',\n",
       " 'NumSources',\n",
       " 'NumArticles',\n",
       " 'AvgTone',\n",
       " 'source']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_col_list = df.columns\n",
    "meta_cols_list = list(df_col_list)\n",
    "meta_cols_list = [\n",
    "    e for e in meta_cols_list if e not in (\n",
    "        'text'\n",
    "        , 'language'\n",
    "        , 'date'\n",
    "        , 'Actor1Name'\n",
    "        , 'Actor2Name'\n",
    "        , 'GoldsteinScale'\n",
    "    )\n",
    "]\n",
    "meta_cols_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18e5bb41-52cd-42dd-b848-d806d3d0e3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:# of chunked documents = 76\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(page_content='text: In this article, we discuss 12 undervalued dividend stocks to buy according to analysts. You can skip our detailed analysis of dividend stocks and their performance over the years, and go directly to read 5 Undervalued Dividend Aristocrats To Buy According to Analysts.\\n\\nDividend aristocrats are the companies in the S&P 500 that have raised their dividends for 25 years or more. Value stocks trade at a lower price relative to their intrinsic value and typically have a lower price-to-earnings ratio. The concept of value investing, popularized by Benjamin Graham and Warren Buffett, revolves around the belief that the market occasionally misprices stocks, leading to opportunities for seasoned investors to buy them at a discount. This investment strategy has proven to be successful over the long haul, delivering a total return of 1,344,600% since 1926, compared with a 626,000% return on growth stocks, as reported by Bank of America.', metadata={'title': '12 Undervalued Dividend Aristocrats To Buy According to Analysts', 'summary': 'In this article, we discuss 12 undervalued dividend stocks to buy according to analysts.\\nYou can skip our detailed analysis of dividend stocks and their performance over the years, and go directly to read 5 Undervalued Dividend Aristocrats To Buy According to Analysts.\\nWhen investing in dividend stocks, many investors find undervalued dividend aristocrat stocks appealing because they offer the potential for both income generation and capital appreciation.\\nIn this article, we will discuss undervalued dividend aristocrats to buy according to analysts.\\n12 Undervalued Dividend Aristocrats To Buy According to Analysts is originally published on Insider Monkey.', 'publish_date': None, 'url': 'https://finance.yahoo.com/news/12-undervalued-dividend-aristocrats-buy-172048478.html', 'NumSources': 0, 'NumArticles': 0, 'AvgTone': 0.0, 'source': 'https://finance.yahoo.com/news/12-undervalued-dividend-aristocrats-buy-172048478.html'})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONTENT_COL_NAME = 'text'\n",
    "\n",
    "docs = me.chunk_bq_table(\n",
    "    bq_dataset_name=MY_BQ_DATASET\n",
    "    , bq_table_name=TABLE_REF\n",
    "    , query=query\n",
    "    , page_content_cols=[CONTENT_COL_NAME]\n",
    "    , metadata_cols=meta_cols_list\n",
    "    , chunk_size=1000\n",
    "    , chunk_overlap=0\n",
    ")\n",
    "\n",
    "texts = [d.page_content for d in docs]\n",
    "metas = [d.metadata for d in docs]\n",
    "\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48200f2-fe8d-4b37-8813-98fbc1d9e943",
   "metadata": {},
   "source": [
    "### Add texts (with metadata)\n",
    "\n",
    "Given a list of texts and metadatas:\n",
    "* assign unique ID to original `<text, metadata>` pair\n",
    "* convert original text into embedding vector representation\n",
    "* upload original text to GCS, where blob name == unique ID and blob metadata == metadata\n",
    "* upsert embedding vector to Matching Engine index, where vector ID == unique ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c029af9-d543-44d3-ad0f-8eee75cd2b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:# of texts = 76\n",
      "INFO:root:# of metadatas = 76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........................................................................\n",
      "len of embeddings: 76\n",
      "len of embeddings[0]: 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Uploaded 76 documents to GCS.\n"
     ]
    }
   ],
   "source": [
    "# chunk text and add to matching engine vector store\n",
    "uploaded_ids = me.add_texts(\n",
    "    texts=texts\n",
    "    , metadatas=metas\n",
    ")\n",
    "\n",
    "uuid_strings = []\n",
    "\n",
    "for uid in uploaded_ids:\n",
    "    uuid_strings.append(str(uid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d115391-3528-4be4-a3e1-709f08d8a45f",
   "metadata": {},
   "source": [
    "### Validate the metadata upload to blob storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a89757b5-4db4-4d65-9a8b-1ed9ab4c89b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "efefbf89-7731-4802-aaa8-7ca68146be61\n",
      "Metadata: {'publish_date': '', 'NumArticles': '0', 'title': '12 Undervalued Dividend Aristocrats To Buy According to Analysts', 'url': 'https://finance.yahoo.com/news/12-undervalued-dividend-aristocrats-buy-172048478.html', 'NumSources': '0', 'AvgTone': '0.0', 'summary': 'In this article, we discuss 12 undervalued dividend stocks to buy according to analysts.\\nYou can skip our detailed analysis of dividend stocks and their performance over the years, and go directly to read 5 Undervalued Dividend Aristocrats To Buy According to Analysts.\\nWhen investing in dividend stocks, many investors find undervalued dividend aristocrat stocks appealing because they offer the potential for both income generation and capital appreciation.\\nIn this article, we will discuss undervalued dividend aristocrats to buy according to analysts.\\n12 Undervalued Dividend Aristocrats To Buy According to Analysts is originally published on Insider Monkey.', 'source': 'https://finance.yahoo.com/news/12-undervalued-dividend-aristocrats-buy-172048478.html'}\n"
     ]
    }
   ],
   "source": [
    "BLOB_UUID = str(uuid_strings[0])\n",
    "print(BLOB_UUID)\n",
    "\n",
    "BLOB_NAME=f'documents/{BLOB_UUID}'\n",
    "test_gcs_blob_metadata(blob_name=BLOB_NAME,bucket_name=EMBEDDING_DIR_BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a20948-d4d5-4e45-b2e5-b6dc6ee2cbb2",
   "metadata": {},
   "source": [
    "## GCSFileLoader\n",
    "Google Cloud Storage FileLoader: The `GCSFileLoader` method supports text, word.docx, ppt, html, pdfs, and images stored as blobs in Google Cloud Storage\n",
    "\n",
    "<center>\n",
    "<img src=\"imgs/chunk_gcs_blobs_flow.png\" width=\"750\"/>\n",
    "</center>\n",
    "\n",
    "To follow along with this example, download the [John Deere 4 R Series manual](http://www.alltractormanuals.com/john-deere/john-deere-4r-series/) and upload it to your GCS bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c64be0f-1051-4adb-9751-72c61bcb125d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE_BLOB = 'docs/OMTR112287_EN_208_Operators_Manual_4044M_4044R_4052M_4052R_4066M_4066R.pdf'\n",
    "\n",
    "# docs = me.chunk_unstructured_gcs_blob(\n",
    "#     blob_name = SOURCE_BLOB\n",
    "#     , bucket_name = BUCKET_NAME\n",
    "# )\n",
    "\n",
    "# texts = [d.page_content for d in docs]\n",
    "# metas = [d.metadata for d in docs]\n",
    "\n",
    "# docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2883c525-0f29-4269-a43f-c1a0e9d6d466",
   "metadata": {},
   "source": [
    "### Add texts (with metadata)\n",
    "\n",
    "Given a list of texts and metadatas:\n",
    "* assign unique ID to original `<text, metadata>` pair\n",
    "* convert original text into embedding vector representation\n",
    "* upload original text to GCS, where blob name == unique ID and blob metadata == metadata\n",
    "* upsert embedding vector to Matching Engine index, where vector ID == unique ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a17a204-41bc-406b-a219-d8e7a80b73c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # chunk text and add to matching engine vector store\n",
    "# uploaded_ids = me.add_texts(\n",
    "#     texts=texts\n",
    "#     , metadatas=metas\n",
    "# )\n",
    "\n",
    "# uuid_strings = []\n",
    "\n",
    "# for uid in uploaded_ids:\n",
    "#     uuid_strings.append(str(uid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea61295b-7047-401c-be45-66e46c15aea0",
   "metadata": {},
   "source": [
    "### Validate metadata upload to blob storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37e12106-a9cd-4db4-a24d-c759b09f9524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLOB_UUID = str(uuid_strings[0])\n",
    "# print(BLOB_UUID)\n",
    "\n",
    "# BLOB_NAME=f'documents/{BLOB_UUID}'\n",
    "# test_gcs_blob_metadata(blob_name=BLOB_NAME,bucket_name=EMBEDDING_DIR_BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3ff9bf-2dd6-4b60-9196-c98f93b3f82a",
   "metadata": {},
   "source": [
    "## YouTube Videos\n",
    "\n",
    "We can transcribe YouTube videos with the [youtube-transcript-api](https://pypi.org/project/youtube-transcript-api/)\n",
    "\n",
    "<center>\n",
    "<img src=\"imgs/chunk_youtube_flow.png\" width=\"1000\"/>\n",
    "</center>\n",
    "\n",
    "* Given a YouTube URL, e.g., `https://www.youtube.com/watch?v=rPq8UsaiR1I`, grab the ID after `watch?v=` (e.g.,`'rPq8UsaiR1I'`)\n",
    "* The transcription returns a list of dicts:\n",
    "```python\n",
    "[\n",
    "    {\n",
    "        'text': 'Hey there',\n",
    "        'start': 7.58,\n",
    "        'duration': 6.13\n",
    "    },\n",
    "    {\n",
    "        'text': 'how are you',\n",
    "        'start': 14.08,\n",
    "        'duration': 7.58\n",
    "    },\n",
    "    # ...\n",
    "]\n",
    "\n",
    "```\n",
    "\n",
    "Sample YouTube videos for this tutorial:\n",
    "* [Time to winterize - 10 tips to prepare your vehicle for Winter](https://www.youtube.com/watch?v=rPq8UsaiR1I)\n",
    "* [The Great Pyramids are power plants](https://www.youtube.com/watch?v=SrT-1y1kyK8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee06d37d-fb32-4fb2-bc7d-acb5af5c4d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:# of pages loaded (pre-chunking) = 1\n",
      "INFO:root:# of documents = 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"Hey, friends, it's Len here from 1A Auto. So, winter's coming, that means inclement\\nweather and, of course, colder temperatures. There's a lot of things on your vehicle you're\\ngoing to need to think about. So, let's go over a few right now. All right. Now, the first thing that we're going to do\\nis get underneath the hood and we're going to start by checking all of our fluids. Go ahead and start on the driver side. Typically, you're going to find your master\\ncylinder and that's going to have your brake fluid in it. Go ahead and take a look from the side and\\nyou'll see where the maximum line is. You can also open the cap and make sure that\\nit looks as though it's clean and clear. Typically, if the fluid starts getting dark\\nbrown in any way, it's time for a flush. Moving along, you'd want to check your oil\\nlevel. There's going to be a little oil dipstick\\nand generally, it'll say engine oil right on it. Go ahead and pull that out, wipe it down,\", metadata={'source': 'https://www.youtube.com/watch?v=rPq8UsaiR1I', 'title': 'Time to Winterize! 10 Tips to Prepare Your Car, Truck, or SUV for Winter', 'description': None, 'view_count': 10974, 'thumbnail_url': 'https://i.ytimg.com/vi/rPq8UsaiR1I/hq720.jpg', 'publish_date': datetime.datetime(2020, 11, 21, 0, 0), 'length': 492, 'author': '1A Auto: Repair Tips & Secrets Only Mechanics Know'})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YOUTUBE_ID='rPq8UsaiR1I'\n",
    "\n",
    "docs = me.chunk_youtube(\n",
    "    youtube_id=YOUTUBE_ID\n",
    ")\n",
    "\n",
    "texts = [d.page_content for d in docs]\n",
    "metas = [d.metadata for d in docs]\n",
    "\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2b7377-1d28-464d-ae35-eb474d2618c7",
   "metadata": {},
   "source": [
    "### Add texts (with metadata)\n",
    "\n",
    "Given a list of texts and metadatas:\n",
    "* assign unique ID to original `<text, metadata>` pair\n",
    "* convert original text into embedding vector representation\n",
    "* upload original text to GCS, where blob name == unique ID and blob metadata == metadata\n",
    "* upsert embedding vector to Matching Engine index, where vector ID == unique ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c89c208-5f23-45de-ab5d-a99b7250082c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:# of texts = 13\n",
      "INFO:root:# of metadatas = 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............\n",
      "len of embeddings: 13\n",
      "len of embeddings[0]: 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Uploaded 13 documents to GCS.\n"
     ]
    }
   ],
   "source": [
    "# chunk text and add to matching engine vector store\n",
    "uploaded_ids = me.add_texts(\n",
    "    texts=texts\n",
    "    , metadatas=metas\n",
    ")\n",
    "\n",
    "uuid_strings = []\n",
    "\n",
    "for uid in uploaded_ids:\n",
    "    uuid_strings.append(str(uid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14456eb-2cf7-4eab-9d9f-1b50bc735c28",
   "metadata": {},
   "source": [
    "### Validate metadata upload to blob storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34bb9fcf-acf4-4d48-a8e6-94abe37fcc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "727ceac0-96c3-4b56-a192-82fc63ce7d33\n",
      "Metadata: {'view_count': '10974', 'author': '1A Auto: Repair Tips & Secrets Only Mechanics Know', 'source': 'https://www.youtube.com/watch?v=rPq8UsaiR1I', 'description': '', 'publish_date': '2020-11-21 00:00:00', 'title': 'Time to Winterize! 10 Tips to Prepare Your Car, Truck, or SUV for Winter', 'length': '492', 'thumbnail_url': 'https://i.ytimg.com/vi/rPq8UsaiR1I/hq720.jpg'}\n"
     ]
    }
   ],
   "source": [
    "BLOB_UUID = str(uuid_strings[0])\n",
    "print(BLOB_UUID)\n",
    "\n",
    "BLOB_NAME=f'documents/{BLOB_UUID}'\n",
    "test_gcs_blob_metadata(blob_name=BLOB_NAME,bucket_name=EMBEDDING_DIR_BUCKET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235e3b4f-e280-4bd1-a28e-5bc0c0430d25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m108"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
