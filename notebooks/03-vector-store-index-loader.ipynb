{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3bc3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba1e071-78ea-44a9-a07d-4ccabe73ec64",
   "metadata": {},
   "source": [
    "# Load Vector Store Index with Data Sources\n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/language/intro_palm_api.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/intro_palm_api.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/blob/main/language/intro_palm_api.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce319cf5",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "<center>\n",
    "<img src=\"imgs/zghost_overview_load_index.png\" width=\"1200\"/>\n",
    "</center>\n",
    "In order for our conversational agent to be able to interact with the GDELT data, we will need to create embeddings on the data that we extracted and insert these newly created vectors into the Matching Engine vector database that was created in notebook 01-setup-vertex-vector-store.\n",
    "\n",
    "Now, we will index the extracted GDELT data (for both event and entity) and load these embeddings into the Vertex AI Matching Engine Vector Store database. Once the embeddings are loaded, we can start experimenting with information retrieval from the Vector Database - including using a Langchain agent.\n",
    "\n",
    "By the end of the notebook, you will be able to perform semantic searches and query against the Vector Store using a Langchain Agent.\n",
    "\n",
    "---\n",
    "\n",
    "### Objectives\n",
    "\n",
    "In this notebook, the steps performed include:\n",
    "\n",
    "- Initialize the previously created Vertex AI Matching Engine resources - if you did not do this already, please see [Setup Vertex Vector Store Notebook]()\n",
    "    - Index\n",
    "    - Endpoint\n",
    "    - Vector Store \n",
    "- Instantiate the Vertex AI Generative AI Language Model \n",
    "    - Embeddings using `textembedding-gecko@001` model\n",
    "    - Using the `MODEL_TEXT_BISON_001` LLM and including stopwords to help prevent hallucinations\n",
    "    - Create the langchain agent by providing the vector store name and description\n",
    "- Semantic Search & Agent Execution against the Vector Store with the ability to cite sources\n",
    "    - Use simple semantic search functionality to return information from the Vector\n",
    "    - Use the langchain agent to answer questions based on the information in the vector store\n",
    "\n",
    "After you have run this notebook, you may want to set up a recurring schedule for extraction of the GDELT data - the [GDELT Pipelines Notebook]() shows how to create an end to end pipeline including updating the Matching Engine Vector store with the latest GDELT data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1175e6f",
   "metadata": {},
   "source": [
    "### Costs\n",
    "This tutorial uses billable components of Google Cloud:\n",
    "\n",
    "* Vertex AI Generative AI Studio\n",
    "* Vertex AI Matching Engine\n",
    "* BigQuery Storage & BigQuery Compute\n",
    "* Google Cloud Storage\n",
    "\n",
    "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing),\n",
    "and use the [Pricing Calculator](https://cloud.google.com/products/calculator/)\n",
    "to generate a cost estimate based on your projected usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc63c51f",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "**Colab only:** Uncomment the following cell to restart the kernel. For Vertex AI Workbench you can restart the terminal using the button on top. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95481d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Automatically restart kernel after installs so that your environment can access the new packages\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b397d1",
   "metadata": {},
   "source": [
    "### Authenticating your notebook environment\n",
    "* If you are using **Colab** to run this notebook, uncomment the cell below and continue.\n",
    "* If you are using **Vertex AI Workbench**, check out the setup instructions [here](https://github.com/GoogleCloudPlatform/generative-ai/tree/main/setup-env)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef694fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb62e47-2fdd-402e-8cd8-20f43a389987",
   "metadata": {},
   "source": [
    "### Make sure you edit the values below\n",
    "Each time you run the notebook for the first time with new variables, you just need to edit the actor prefix and version variables below. They are needed to grab all the other variables in the notebook configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3097b433-9742-423c-853c-2f9eefa928d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTOR_PREFIX       : ggl\n",
      "VERSION            : v1\n"
     ]
    }
   ],
   "source": [
    "# CREATE_NEW_ASSETS        = True # True | False\n",
    "ACTOR_PREFIX             = \"ggl\"\n",
    "VERSION                  = 'v1'\n",
    "\n",
    "# print(f\"CREATE_NEW_ASSETS  : {CREATE_NEW_ASSETS}\")\n",
    "print(f\"ACTOR_PREFIX       : {ACTOR_PREFIX}\")\n",
    "print(f\"VERSION            : {VERSION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c21c11b-fada-4bb0-8a3d-733a43f1bcb7",
   "metadata": {},
   "source": [
    "### Load configuration settings from setup notebook\n",
    "> Set the constants used in this notebook and load the config settings from the `00-env-setup.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be210a85-ca0e-49dd-a75a-556ae66211e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"wortz-project-352116\"\n",
      "PROJECT_NUM              = \"679926387543\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"me-network\"\n",
      "\n",
      "CREATE_NEW_ASSETS        = \"True\"\n",
      "ACTOR_PREFIX             = \"ggl\"\n",
      "VERSION                  = \"v1\"\n",
      "ACTOR_NAME               = \"google\"\n",
      "ACTOR_CATEGORY           = \"technology\"\n",
      "\n",
      "BUCKET_NAME              = \"zghost-ggl-v1-wortz-project-352116\"\n",
      "EMBEDDING_DIR_BUCKET     = \"zghost-ggl-v1-wortz-project-352116-emd-dir\"\n",
      "\n",
      "BUCKET_URI               = \"gs://zghost-ggl-v1-wortz-project-352116\"\n",
      "EMBEDDING_DIR_BUCKET_URI = \"gs://zghost-ggl-v1-wortz-project-352116-emd-dir\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/679926387543/global/networks/me-network\"\n",
      "\n",
      "ME_INDEX_NAME            = \"vectorstore_ggl_v1\"\n",
      "ME_INDEX_ENDPOINT_NAME   = \"vectorstore_ggl_v1_endpoint\"\n",
      "ME_DIMENSIONS            = \"768\"\n",
      "\n",
      "MY_BQ_DATASET            = \"zghost_ggl_v1\"\n",
      "MY_BQ_TRENDS_DATASET     = \"zghost_ggl_v1_trends\"\n",
      "\n",
      "BUCKET_NAME        : zghost-ggl-v1-wortz-project-352116\n",
      "BUCKET_URI         : gs://zghost-ggl-v1-wortz-project-352116\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "BUCKET_NAME              = f'zghost-{ACTOR_PREFIX}-{VERSION}-{PROJECT_ID}'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)\n",
    "\n",
    "print(f\"BUCKET_NAME        : {BUCKET_NAME}\")\n",
    "print(f\"BUCKET_URI         : {BUCKET_URI}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b4cf14-3e7e-42bd-be0e-0d2bac9257e5",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6b06e4f-a16a-48ea-9d6b-93304d495fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"..\")\n",
    "# helper classes for using the langchain agent, LLM class, and embeddings model\n",
    "from zeitghost.agents.LangchainAgent import LangchainAgent\n",
    "from zeitghost.vertex.LLM import VertexLLM\n",
    "from zeitghost.vertex.Embeddings import VertexEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffdf66df-ff35-4bfb-8fbf-5db6bbdb70ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform as vertex_ai\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "\n",
    "from langchain.document_loaders import DataFrameLoader\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import io\n",
    "\n",
    "from IPython.display import display, Image, Markdown\n",
    "from PIL import Image, ImageDraw\n",
    "import logging\n",
    "logging.basicConfig(level = logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94726e2a-478a-45d7-9191-ab97925b2311",
   "metadata": {},
   "source": [
    "Instantiate Google Cloud SDK clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dfea060-8ac4-4cd5-8026-b372752f3e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "vertex_ai.init(project=PROJECT_ID,location=LOCATION)\n",
    "\n",
    "# bigquery client\n",
    "bqclient = bigquery.Client(\n",
    "    project=PROJECT_ID,\n",
    "    # location=LOCATION\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbffd10",
   "metadata": {},
   "source": [
    "Helper function for inspecting blob data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ee21a33-e720-4fa8-b4f5-f92e4981c8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_gcs_blob_metadata(blob_name, bucket_name):\n",
    "    \"\"\"\n",
    "    inspect blobs uploaded to GCS\n",
    "    \"\"\"\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.get_blob(blob_name)\n",
    "    print(f\"Metadata: {blob.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630aa574",
   "metadata": {},
   "source": [
    "## Initialize Vertex AI Matching Engine & GenAI Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca52a2e-b7da-4d72-97a1-3e6dff11e2fe",
   "metadata": {},
   "source": [
    "### Matching Engine Index and IndexEndpoint\n",
    "Initialize the Vertex AI Matching Engine resources. You should have already created these resources in the [Setup Vertex Vector Store]() notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7863051-b16b-4783-ad92-868e54a7fb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zeitghost.vertex.MatchingEngineCRUD import MatchingEngineCRUD\n",
    "\n",
    "mengine = MatchingEngineCRUD(\n",
    "    project_id=PROJECT_ID \n",
    "    , project_num=PROJECT_NUM\n",
    "    , region=LOCATION \n",
    "    , index_name=ME_INDEX_NAME\n",
    "    , vpc_network_name=VPC_NETWORK_FULL\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ebf9ff",
   "metadata": {},
   "source": [
    "Update the variable values and print out the matching engine resource information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3fb016b-0d55-4548-bcc1-a5e680e8b290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ME_INDEX_RESOURCE_NAME  = projects/939655404703/locations/us-central1/indexes/5031884178191286272\n",
      "ME_INDEX_ENDPOINT_ID    = projects/939655404703/locations/us-central1/indexEndpoints/3175838181761220608\n",
      "ME_INDEX_ID             = 5031884178191286272\n"
     ]
    }
   ],
   "source": [
    "ME_INDEX_RESOURCE_NAME, ME_INDEX_ENDPOINT_ID = mengine.get_index_and_endpoint()\n",
    "ME_INDEX_ID=ME_INDEX_RESOURCE_NAME.split(\"/\")[5]\n",
    "\n",
    "print(f\"ME_INDEX_RESOURCE_NAME  = {ME_INDEX_RESOURCE_NAME}\")\n",
    "print(f\"ME_INDEX_ENDPOINT_ID    = {ME_INDEX_ENDPOINT_ID}\")\n",
    "print(f\"ME_INDEX_ID             = {ME_INDEX_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acb6ba3",
   "metadata": {},
   "source": [
    "Uncomment the cell below to optionally list out existing index endpoints in your project and region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4722f43c-69ee-4974-ae90-d6a346b33362",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !gcloud ai index-endpoints list --project=$PROJECT_ID --region=$LOCATION\n",
    "\n",
    "# endpoint_data = ! gcloud ai index-endpoints list --region {LOCATION} --filter {ME_INDEX_ENDPOINT_ID}\n",
    "# endpoint_address = [e for e in endpoint_data if 'publicEndpointDomainName' in e][0].partition(': ')[2] #careful - this is grabbing the first one in the list\n",
    "# endpoint_address"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6a9b28",
   "metadata": {},
   "source": [
    "Either create a new index endpoint or use an existing one - if you already created it in the Setup Vertex Vector notebook, you should see that the Index endpoint already exists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e40ca02-2099-4727-99ca-2681309c27a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Index endpoint already exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index endpoint resource name: projects/939655404703/locations/us-central1/indexEndpoints/3175838181761220608\n",
      "Index endpoint public domain name: \n",
      "Deployed indexes on the index endpoint:\n",
      "    vectorstore_ggl_v1_20230614201535\n"
     ]
    }
   ],
   "source": [
    "index_endpoint = mengine.create_index_endpoint()\n",
    "\n",
    "if index_endpoint:\n",
    "    print(f\"Index endpoint resource name: {index_endpoint.name}\")\n",
    "    print(f\"Index endpoint public domain name: {index_endpoint.public_endpoint_domain_name}\")\n",
    "    print(f\"Deployed indexes on the index endpoint:\")\n",
    "    for d in index_endpoint.deployed_indexes:\n",
    "        print(f\"    {d.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd96c257-aed3-4083-875f-9031c383730e",
   "metadata": {},
   "source": [
    "### Vertex AI LLM & Embeddings Generator\n",
    "\n",
    "Instantiate the Vertex AI LLMs using the helper classes, with different parameters passed to be used for different scenarios\n",
    "\n",
    "For more information on parameters such as temperature, top_p, top_k, see [Getting Started with the Vertex AI PaLM API & Python SDK](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/intro_palm_api.ipynb)\n",
    "\n",
    "*  `stop=None`: in this case, we are NOT passing a stopword when calling the LLM\n",
    "* `stop=['Observation:']`: in this case, we are stopping when the LLM response shows <i>Observation:</i> to avoid hallucinations from the BigQuery and Pandas agents\n",
    "* `strip=True`: we've noticed that when working with PaLM + BigQuery Langchain Agents, enabling string parsing stripping capabilities can prevent hallucinations \n",
    "\n",
    "To read more about different types of agents, see the [Langchain Documentation on Agents](https://python.langchain.com/en/latest/modules/agents.html)\n",
    "\n",
    "Make sure your REQUESTS_PER_MINUTE does not exceed your project quota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1762e36-d94e-4e2b-8f00-0e14cf710059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = VertexLLM(\n",
    "#     stop=None \n",
    "#     , temperature=0.0\n",
    "#     , max_output_tokens=1000\n",
    "#     , top_p=0.7\n",
    "#     , top_k=40\n",
    "# )\n",
    "\n",
    "llm = VertexLLM(\n",
    "    temperature=0\n",
    "    , stop=['Observation:']\n",
    "    # , stop=None\n",
    "    , strip=True\n",
    "    , strip_chars=['\\\\', '\\\\\\\\']\n",
    "    , max_output_tokens=1000\n",
    "    , top_p=0.7\n",
    "    , top_k=40\n",
    ")\n",
    "\n",
    "langchain_llm_for_bq = VertexLLM(\n",
    "    stop=['Observation:'] \n",
    "    , strip=True \n",
    "    , temperature=0.0\n",
    "    , max_output_tokens=1000\n",
    "    , top_p=0.7\n",
    "    , top_k=40\n",
    ")\n",
    "\n",
    "langchain_llm_for_pandas = VertexLLM(\n",
    "    stop=['Observation:']\n",
    "    , strip=False\n",
    "    , temperature=0.0\n",
    "    , max_output_tokens=1000\n",
    "    , top_p=0.7\n",
    "    , top_k=40\n",
    ")\n",
    "REQUESTS_PER_MINUTE = 299 # project quota==300\n",
    "vertex_embedding = VertexEmbeddings(requests_per_minute=REQUESTS_PER_MINUTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfd6a5e-291e-4832-9e0d-9eafea19aaed",
   "metadata": {},
   "source": [
    "Let's ping the LLM and verify we are getting a response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afc19784-3cb1-4b5f-84df-eb280fdffaa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Widespread Panic is an American rock band formed in Athens, Georgia, in 1986. The band\\'s lineup consists of John Bell (vocals, guitar), Jimmy Herring (guitar, vocals), Dave Schools (bass), John \"JoJo\" Hermann (keyboards), and Duane Trucks (drums). Widespread Panic has released 15 studio albums, four live albums, and two compilation albums.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# llm.predict('how are you doing today?')\n",
    "llm('In no more than 50 words, what can you tell me about the band Widespread Panic?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6b8a28-0a18-4674-ae6f-bbe5d0f86cfb",
   "metadata": {},
   "source": [
    "### Initialize Matching Engine VectorStore\n",
    "In this notebook we will import the MatchingEngineVector class which will:\n",
    "- Enable streaming index updates to a Matching Engine Index\n",
    "- While the embeddings are stored in the Matching Engine, the embedded documents will be stored in GCS.     \n",
    "    - An existing Index and corresponding Endpoint are preconditions for\n",
    "    using this module.\n",
    "    - See usage in docs/modules/indexes/vectorstores/examples/matchingengine.ipynb\n",
    "    - Note that this implementation is mostly meant for reading if you are\n",
    "    planning to do a real time implementation. While reading is a real time\n",
    "    operation, updating the index takes close to one hour.\n",
    "- Note: at current time of writing, creating ME index from LangChain only supports batch index updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f8cd39d-e282-4e33-9a0c-7058cd6724b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zeitghost.vertex.MatchingEngineVectorstore import MatchingEngineVectorStore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a285ca",
   "metadata": {},
   "source": [
    "Initialize the Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c72e2aa9-b13f-4249-bea6-8d84028da291",
   "metadata": {},
   "outputs": [],
   "source": [
    "me = MatchingEngineVectorStore.from_components(\n",
    "    project_id=PROJECT_ID\n",
    "    # , project_num=PROJECT_NUM\n",
    "    , region=LOCATION\n",
    "    , gcs_bucket_name=EMBEDDING_DIR_BUCKET_URI\n",
    "    , embedding=vertex_embedding\n",
    "    , index_id=ME_INDEX_ID\n",
    "    , endpoint_id=ME_INDEX_ENDPOINT_ID\n",
    "    , k = 10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6a5f10",
   "metadata": {},
   "source": [
    "Verify the Vertex Embeddings & Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "081ac862-d8b1-4e37-9f2f-89d9ecd78d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zeitghost.vertex.Embeddings.VertexEmbeddings at 0x7fc3642bc820>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "me.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "884f3822-05d3-4a67-96c1-28ced9ca69cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.matching_engine.matching_engine_index_endpoint.MatchingEngineIndexEndpoint object at 0x7fc364358550> \n",
       "resource name: projects/939655404703/locations/us-central1/indexEndpoints/3175838181761220608"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "me.endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d9f5a5-f133-44eb-a91e-a03ba3699ab1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Index GDELT BigQuery Tables\n",
    "Now that you have extracted the Event & Entity GDELT data into BigQuery, we create Vectors that will be streamed into the Vertex AI Matching Engine Index "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fdfeb5-9c71-4052-9f1f-2718c2bdb776",
   "metadata": {
    "tags": []
   },
   "source": [
    "### GDELT Events Table\n",
    "Update the variable values for the previously created GDELT events tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45e58560-1cc3-4805-bfb5-2a5554b6d89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GDELT_TABLE_NAME         : test_events_gdelt_ggl_v1\n",
      "GDELT_TABLE_REF          : cpg-cdp.zghost_ggl_v1.test_events_gdelt_ggl_v1\n",
      "SCRAPED_GDELT_TABLE_REF  : cpg-cdp.zghost_ggl_v1.scraped_test_events_gdelt_ggl_v1\n"
     ]
    }
   ],
   "source": [
    "GDELT_TABLE_NAME                 = f'test_events_gdelt_{ACTOR_PREFIX}_{VERSION}'\n",
    "\n",
    "GDELT_TABLE_REF                  = f'{PROJECT_ID}.{MY_BQ_DATASET}.{GDELT_TABLE_NAME}'\n",
    "SCRAPED_GDELT_TABLE_REF          = f'{PROJECT_ID}.{MY_BQ_DATASET}.scraped_{GDELT_TABLE_NAME}'\n",
    "\n",
    "print(f\"GDELT_TABLE_NAME         : {GDELT_TABLE_NAME}\")\n",
    "print(f\"GDELT_TABLE_REF          : {GDELT_TABLE_REF}\")\n",
    "print(f\"SCRAPED_GDELT_TABLE_REF  : {SCRAPED_GDELT_TABLE_REF}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3c5c84",
   "metadata": {},
   "source": [
    "Let's preview some of this data before creating the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ef28e5b-d711-468e-9f10-25b26942c782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>url</th>\n",
       "      <th>language</th>\n",
       "      <th>date</th>\n",
       "      <th>Actor1Name</th>\n",
       "      <th>Actor2Name</th>\n",
       "      <th>GoldsteinScale</th>\n",
       "      <th>NumMentions</th>\n",
       "      <th>NumSources</th>\n",
       "      <th>NumArticles</th>\n",
       "      <th>AvgTone</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chinese Threat Actor Abused ESXi Zero-Day to P...</td>\n",
       "      <td>A Chinese cyber-espionage group that researche...</td>\n",
       "      <td>The malware bundle also allowed UNC3886 actor ...</td>\n",
       "      <td>2023-06-13 22:00:00+00:00</td>\n",
       "      <td>https://www.darkreading.com/attacks-breaches/c...</td>\n",
       "      <td>en</td>\n",
       "      <td>20230614</td>\n",
       "      <td>VMWARE</td>\n",
       "      <td>VMWARE</td>\n",
       "      <td>2.3499999999999996</td>\n",
       "      <td>[3]</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-3.42465753424657</td>\n",
       "      <td>https://www.darkreading.com/attacks-breaches/c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Chinese Threat Actor Abused ESXi Zero-Day to P...   \n",
       "\n",
       "                                                text  \\\n",
       "0  A Chinese cyber-espionage group that researche...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  The malware bundle also allowed UNC3886 actor ...   \n",
       "\n",
       "                publish_date  \\\n",
       "0  2023-06-13 22:00:00+00:00   \n",
       "\n",
       "                                                 url language      date  \\\n",
       "0  https://www.darkreading.com/attacks-breaches/c...       en  20230614   \n",
       "\n",
       "  Actor1Name Actor2Name      GoldsteinScale NumMentions NumSources  \\\n",
       "0     VMWARE     VMWARE  2.3499999999999996         [3]          1   \n",
       "\n",
       "  NumArticles            AvgTone  \\\n",
       "0           3  -3.42465753424657   \n",
       "\n",
       "                                              source  \n",
       "0  https://www.darkreading.com/attacks-breaches/c...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "    SELECT * \n",
    "    FROM `{SCRAPED_GDELT_TABLE_REF}`\n",
    "    -- LIMIT 5\n",
    "\"\"\"\n",
    "df=bqclient.query(query).to_dataframe().head(1)\n",
    "\n",
    "df_col_list = df.columns\n",
    "meta_cols_list = list(df_col_list)\n",
    "meta_cols_list.remove('text')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec44810",
   "metadata": {},
   "source": [
    "List out the metadata columns - we will be providing this metadata information to the conversational agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "527fcea1-ebb7-4766-85a6-96d509d41edc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['title',\n",
       " 'summary',\n",
       " 'publish_date',\n",
       " 'url',\n",
       " 'language',\n",
       " 'date',\n",
       " 'Actor1Name',\n",
       " 'Actor2Name',\n",
       " 'GoldsteinScale',\n",
       " 'NumMentions',\n",
       " 'NumSources',\n",
       " 'NumArticles',\n",
       " 'AvgTone',\n",
       " 'source']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_cols_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9e65fe",
   "metadata": {},
   "source": [
    "Create the embeddings and write out to a GCS bucket to be used for insert into the Matching Engine Vector Store\n",
    "\n",
    "After this job completes, you will see how many documents were chunked, how long it took, and confirmation that this was uploaded to cloud storage.\n",
    "Example: \n",
    "\n",
    "```\n",
    "INFO:root:# of chunked documents = 60\n",
    "INFO:root:# of texts = 60\n",
    "INFO:root:# of metadatas = 60\n",
    "elapsed time: 1.0051262378692627\n",
    "...........................................................\n",
    "len of embeddings: 60\n",
    "len of embeddings[0]: 768\n",
    "INFO:root:Uploaded 60 documents to GCS.\n",
    "60\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed6fe8ea-7f18-4739-a8e9-dde71450a128",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:# of chunked documents = 60\n",
      "INFO:root:# of texts = 60\n",
      "INFO:root:# of metadatas = 60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 1.0051262378692627\n",
      "...........................................................\n",
      "len of embeddings: 60\n",
      "len of embeddings[0]: 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Uploaded 60 documents to GCS.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "docs = me.chunk_bq_table(\n",
    "    bq_dataset_name=MY_BQ_DATASET\n",
    "    , bq_table_name=SCRAPED_GDELT_TABLE_REF\n",
    "    , query=query\n",
    "    , page_content_cols=['text']\n",
    "    , metadata_cols=meta_cols_list\n",
    "    , chunk_size=2000\n",
    "    , chunk_overlap=0\n",
    ")\n",
    "\n",
    "end = time.time()\n",
    "print(f\"elapsed time: {end - start}\")\n",
    "\n",
    "texts = [d.page_content for d in docs]\n",
    "metas = [d.metadata for d in docs]\n",
    "\n",
    "# chunk text and add to matching engine vector store\n",
    "uploaded_ids = me.add_texts(\n",
    "    texts=texts\n",
    "    , metadatas=metas\n",
    ")\n",
    "\n",
    "uuid_strings = []\n",
    "\n",
    "for uid in uploaded_ids:\n",
    "    uuid_strings.append(str(uid))\n",
    "    \n",
    "print(len(uuid_strings))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478e0bfb",
   "metadata": {},
   "source": [
    "Sample the text values - you should see the resulting text value from an article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5864a44-c1ce-41b4-992d-786441ad2784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text: BRUSSELS (AP) — European Union regulators hit Google with fresh antitrust charges Wednesday, saying the only way to satisfy competition concerns about its lucrative digital ad business is by selling off parts of the tech giant’s main moneymaker.\\n\\nThe unprecedented decision to push for such a breakup marks a significant escalation by Brussels in its crackdown on Silicon Valley digital giants.\\n\\nThe European Commission, the bloc’s executive branch and top antitrust enforcer, said its preliminary view after an investigation is that “only the mandatory divestment by Google of part of its services” would satisfy the concerns.\\n\\nThe 27-nation EU has led the global movement to crack down on Big Tech companies — including groundbreaking rules on artificial intelligence — but it has previously relied on issuing blockbuster fines, including three antitrust penalties for Google worth billions of euros (dollars).\\n\\nIt’s the first time the bloc has told a tech giant that it should split up key parts of its business over violations of the EU’s strict antitrust laws, though details on what that could look like are not clear following the preliminary finding.\\n\\nEuropean Commissioner for Europe fit for the Digital Age Margrethe Vestager speaks during a media conference regarding an antitrust case against Google Adtech at EU headquarters in Brussels, Wednesday, June 14, 2023. (AP Photo/Virginia Mayo) Photo: ASSOCIATED PRESS/Virginia Mayo\\n\\nGoogle can now defend itself by making its case before the commission issues its final decision. The company said it disagreed with the decision and “will respond accordingly,” adding that the EU’s investigation focusing on a narrow part of its ad business.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bc9ea7",
   "metadata": {},
   "source": [
    "Inspect the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8720281f-4d9d-4ca2-a718-fc5ae97763e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31048973-5b3a-48e6-a810-1bf4f7b83350\n",
      "Metadata: {'Actor1Name': 'VMWARE', 'NumSources': '1', 'NumArticles': '3', 'AvgTone': '-3.42465753424657', 'source': 'https://www.darkreading.com/attacks-breaches/chinese-threat-actor-abused-esxi-zero-day-pilfer-files-guest-vms', 'summary': 'The malware bundle also allowed UNC3886 actor to tamper with the hypervisor\\'s logging service and to execute arbitrary commend between guest VMs on the same hypervisor.\\nMandiant\\'s analysis at the time showed the threat actor required admin-level privileges on the ESXi hypervisor to deploy the backdoors.\\nThe threat actor targeted ESXi hosts belonging to defense, technology and telecommunications companies, Mandiant said.\\nOnce connected to the ESXi hosts, the threat actor leveraged CVE-2023-20867 to run commands and transfer files on running guest machines without the need for the guest’s credentials, he says.\\n\"UNC3886 has shown itself to be a flexible, yet highly capable threat actor, which will modify open source projects to complete their mission,\" he says.', 'publish_date': '2023-06-13 22:00:00+00:00', 'language': 'en', 'GoldsteinScale': '2.3499999999999996', 'date': '20230614', 'title': 'Chinese Threat Actor Abused ESXi Zero-Day to Pilfer Files From Guest VMs', 'Actor2Name': 'VMWARE', 'url': 'https://www.darkreading.com/attacks-breaches/chinese-threat-actor-abused-esxi-zero-day-pilfer-files-guest-vms', 'NumMentions': '[3]'}\n"
     ]
    }
   ],
   "source": [
    "BLOB_UUID = str(uuid_strings[0])\n",
    "print(BLOB_UUID)\n",
    "\n",
    "BLOB_NAME=f'documents/{BLOB_UUID}'\n",
    "test_gcs_blob_metadata(blob_name=BLOB_NAME,bucket_name=EMBEDDING_DIR_BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ecd4dc-b0a3-4d87-8fe3-0e2a967de131",
   "metadata": {},
   "source": [
    "### Global Entity Graph (GEG) articles\n",
    "We'll now perform a similar workflow to extract the entity graph articles \n",
    "\n",
    "First set the variables based on the previously created GDELT entity tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a71221cb-2ae2-472e-a9af-590ee5442d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GDELT_TABLE_NAME         : test_geg_articles_ggl_v1\n",
      "GDELT_TABLE_REF          : cpg-cdp.zghost_ggl_v1.test_geg_articles_ggl_v1\n",
      "SCRAPED_GDELT_TABLE_REF  : cpg-cdp.zghost_ggl_v1.scraped_test_geg_articles_ggl_v1\n"
     ]
    }
   ],
   "source": [
    "GDELT_TABLE_NAME                 = f'test_geg_articles_{ACTOR_PREFIX}_{VERSION}'\n",
    "\n",
    "GDELT_TABLE_REF                  = f'{PROJECT_ID}.{MY_BQ_DATASET}.{GDELT_TABLE_NAME}'\n",
    "SCRAPED_GDELT_TABLE_REF          = f'{PROJECT_ID}.{MY_BQ_DATASET}.scraped_{GDELT_TABLE_NAME}'\n",
    "\n",
    "print(f\"GDELT_TABLE_NAME         : {GDELT_TABLE_NAME}\")\n",
    "print(f\"GDELT_TABLE_REF          : {GDELT_TABLE_REF}\")\n",
    "print(f\"SCRAPED_GDELT_TABLE_REF  : {SCRAPED_GDELT_TABLE_REF}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4133e238",
   "metadata": {},
   "source": [
    "Let's sample the data before creating embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd7a4722-df8b-4bb9-9486-7b04e1d23998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>url</th>\n",
       "      <th>language</th>\n",
       "      <th>date</th>\n",
       "      <th>Actor1Name</th>\n",
       "      <th>Actor2Name</th>\n",
       "      <th>GoldsteinScale</th>\n",
       "      <th>NumSources</th>\n",
       "      <th>NumArticles</th>\n",
       "      <th>AvgTone</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google Search agrees to pay $23 million settle...</td>\n",
       "      <td>People who searched using Google and clicked o...</td>\n",
       "      <td>People who searched using Google and clicked o...</td>\n",
       "      <td>2023-06-13 00:00:00+00:00</td>\n",
       "      <td>https://www.cincinnati.com/story/money/2023/06...</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://www.cincinnati.com/story/money/2023/06...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Google Search agrees to pay $23 million settle...   \n",
       "\n",
       "                                                text  \\\n",
       "0  People who searched using Google and clicked o...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  People who searched using Google and clicked o...   \n",
       "\n",
       "               publish_date  \\\n",
       "0 2023-06-13 00:00:00+00:00   \n",
       "\n",
       "                                                 url language date Actor1Name  \\\n",
       "0  https://www.cincinnati.com/story/money/2023/06...       en                   \n",
       "\n",
       "  Actor2Name GoldsteinScale  NumSources  NumArticles  AvgTone  \\\n",
       "0                                     0            0      0.0   \n",
       "\n",
       "                                              source  \n",
       "0  https://www.cincinnati.com/story/money/2023/06...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = f\"\"\"\n",
    "    SELECT * \n",
    "    FROM `{SCRAPED_GDELT_TABLE_REF}`\n",
    "    -- LIMIT 5\n",
    "\"\"\"\n",
    "df=bqclient.query(query).to_dataframe().head(1)\n",
    "\n",
    "df_col_list = df.columns\n",
    "meta_cols_list = list(df_col_list)\n",
    "# meta_cols_list.remove('text')\n",
    "meta_cols_list = [\n",
    "    e for e in meta_cols_list if e not in (\n",
    "        'text'\n",
    "        , 'language'\n",
    "        , 'date'\n",
    "        , 'Actor1Name'\n",
    "        , 'Actor2Name'\n",
    "        , 'GoldsteinScale'\n",
    "    )\n",
    "]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3026cc54",
   "metadata": {},
   "source": [
    "List out the column metadata - remember this will also be provided to the conversational agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a066615-20f9-4bf5-a0c7-eb5dad6d253d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['title',\n",
       " 'summary',\n",
       " 'publish_date',\n",
       " 'url',\n",
       " 'NumSources',\n",
       " 'NumArticles',\n",
       " 'AvgTone',\n",
       " 'source']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_cols_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f139f69b",
   "metadata": {},
   "source": [
    "Create the embeddings and write out to a GCS bucket to be used for insert into the Matching Engine Vector Store\n",
    "\n",
    "Example output will have input about the number of docs loaded, how long it took, successful upload to GCS:\n",
    "```\n",
    "INFO:root:# of chunked documents = 40\n",
    "INFO:root:# of texts = 40\n",
    "INFO:root:# of metadatas = 40\n",
    "elapsed time: 0.6589460372924805\n",
    ".......................................\n",
    "len of embeddings: 40\n",
    "len of embeddings[0]: 768\n",
    "INFO:root:Uploaded 40 documents to GCS.\n",
    "40\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1bbe50af-bf8b-4fdf-8c56-e795fd82eed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:# of chunked documents = 40\n",
      "INFO:root:# of texts = 40\n",
      "INFO:root:# of metadatas = 40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 0.6589460372924805\n",
      ".......................................\n",
      "len of embeddings: 40\n",
      "len of embeddings[0]: 768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Uploaded 40 documents to GCS.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "docs = me.chunk_bq_table(\n",
    "    bq_dataset_name=MY_BQ_DATASET\n",
    "    , bq_table_name=SCRAPED_GDELT_TABLE_REF\n",
    "    , query=query\n",
    "    , page_content_cols=['text']\n",
    "    , metadata_cols=meta_cols_list\n",
    "    , chunk_size=1000\n",
    "    , chunk_overlap=0\n",
    ")\n",
    "\n",
    "end = time.time()\n",
    "print(f\"elapsed time: {end - start}\")\n",
    "\n",
    "texts = [d.page_content for d in docs]\n",
    "metas = [d.metadata for d in docs]\n",
    "\n",
    "# # chunk article text and add to Matching Engine Vector Store\n",
    "uploaded_ids = me.add_texts(\n",
    "    texts=texts\n",
    "    , metadatas=metas\n",
    ")\n",
    "\n",
    "uuid_strings = []\n",
    "\n",
    "for uid in uploaded_ids:\n",
    "    uuid_strings.append(str(uid))\n",
    "    \n",
    "print(len(uuid_strings))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3f6bbe",
   "metadata": {},
   "source": [
    "Let's sample a text value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7fae8c3a-1d9f-4c30-8292-60d2d951b30c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To opt out or into of the settlement, visit refererheadersettlement.com.\\n\\nTo opt out the settlement, click on the Exclusion Form page, where you will register to receive a Class Member ID.\\n\\nTo opt into the settlement, click on the Registration Form page. Fill out your information and submit it to receive a Class Member ID at your email provided in your registration form. You'll then go to the Submit Claim page, where you can enter your Class Member ID and submit the form to file your claim.\\n\\nHow much is the payment for?\\n\\nBased on current data, the payment amounts for those with approved claims is expected to be around $7.70 per person.\\n\\nWhen can I expect the settlement to be finalized?\\n\\nThe final approval hearing for the settlement is currently scheduled for Oct. 12. Users who wish to object the settlement have to write to the court about why they disapprove of it by July 31, and can also ask to speak in court on the issue.\\n\\nHow is Google changing following the lawsuit?\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86157669",
   "metadata": {},
   "source": [
    "Inspect the metadata in blob storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b322dc9-aa48-411b-ab15-fa3321078d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9c33b1bc-e8b3-4cc2-baf2-11e4c72d1d9f\n",
      "Metadata: {'title': 'Google Search agrees to pay $23 million settlement and you may be entitled to a portion', 'NumArticles': '0', 'publish_date': '2023-06-13 00:00:00+00:00', 'AvgTone': '0.0', 'summary': 'People who searched using Google and clicked on search results between October 2006 and September 2013 may be entitled to receive a cut of a $23 million settlement Google has agreed to pay.\\nPeople who used Google Search and clicked on a search result link between or on Oct. 26, 2006 and Sept. 30, 2013 are included in the settlement as a settlement class member.\\nSettlement class members have to decide to participate by July 31.\\nTo opt out the settlement, click on the Exclusion Form page, where you will register to receive a Class Member ID.\\nFollowing the settlement, Google will change its frequently asked questions (FAQs) and key terms pages to explain the circumstances under which search queries are shared with third parties using referrer headers.', 'NumSources': '0', 'source': 'https://www.cincinnati.com/story/money/2023/06/13/google-settlement-search-payout/70318406007/', 'url': 'https://www.cincinnati.com/story/money/2023/06/13/google-settlement-search-payout/70318406007/'}\n"
     ]
    }
   ],
   "source": [
    "BLOB_UUID = str(uuid_strings[0])\n",
    "print(BLOB_UUID)\n",
    "\n",
    "BLOB_NAME=f'documents/{BLOB_UUID}'\n",
    "test_gcs_blob_metadata(blob_name=BLOB_NAME,bucket_name=EMBEDDING_DIR_BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc152d6-5867-468c-b75c-377420a781d1",
   "metadata": {},
   "source": [
    "## Test streaming updates with Semantic Search and Action Agents\n",
    "\n",
    "Because we created a Vertex Matching Engine index with streaming updates, we can query our index and expect the documents we just uploaded (above) to immediately be considered for the LLM to synthesize answers given a prompt \n",
    "\n",
    "1. We'll start with a generic semantic search, given a query. This will return `k` relevant documents (and their source URL/URI)\n",
    "\n",
    "2. We'll build on this idea with [Agents](https://python.langchain.com/en/latest/modules/agents.html):\n",
    "\n",
    "* Some user input is received\n",
    "* The agent decides which tool - if any - to use, and what the input to that tool should be\n",
    "* That tool is then called with that tool input, and an observation is recorded (this is just the output of calling that tool with that tool input)\n",
    "* That history of tool, tool input, and observation is passed back into the agent, and it decides what step to take next\n",
    "* This is repeated until the agent decides it no longer needs to use a tool, and then it responds directly to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a406d721-0808-434a-8f63-fc8e0f4480db",
   "metadata": {},
   "source": [
    "### Semantic search\n",
    "Using the similarity_search helper function in Zeitghost.Vertex.MatchingEngineVectorStore, we can perform a simple semantic search.\n",
    "\n",
    "Args:\n",
    "- query: The string that will be used to search for similar documents.\n",
    "- k: The amount of neighbors that will be retrieved.\n",
    "\n",
    "Returns:\n",
    "- A list of k matching documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6b719c",
   "metadata": {},
   "source": [
    "Uncomment to print the endpoint name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2afb3ea3-d68f-4f73-afd9-c69a4377c84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# me.endpoint.public_endpoint_domain_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b16281",
   "metadata": {},
   "source": [
    "We have some preloaded semantic search prompts in the windows below, but feel free to change them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "056d9ac4-79e6-4c86-9c52-7aef082b1b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Embedding query What are some of googles recent board appointments?.\n",
      "INFO:root:Deployed Index ID = vectorstore_ggl_v1_20230614201535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='text: European Union (EU) antitrust officials made a groundbreaking ruling on Wednesday, June 14, by suggesting the internet giant Google sell off a portion of its profitable digital advertising business due to competition concerns.\\n\\nAfter conducting an inquiry, the European Commission (EC), which is the bloc\\'s executive body and top antitrust enforcer, came to the conclusion that \"only the mandatory divestment by Google of part of its services\" would address the issue.\\n\\nThe EU\\'s 27 member states have been at the forefront of the international effort to regulate tech giants like Facebook, Google, and Amazon by passing groundbreaking regulations on AI and issuing massive fines in the past.\\n\\nHistoric EU Decision to Order Business Units to Break Up\\n\\nAccording to ABC News, this is the first time the EU has ordered a tech company to break up major elements of its business for violating the EU\\'s stringent antitrust regulations. However, the specifics of this order have not been made public.\\n\\nNow that the commission has given Google the opportunity to respond, it may present its case in defense. The corporation has said that it disagrees with the conclusion and will respond accordingly since the EU inquiry only pertains to a small portion of the company\\'s advertising operations.\\n\\nAccording to Dan Taylor, Google\\'s vice president of global ads, \"Our advertising technology tools help websites and apps fund their content and enable businesses of all sizes to effectively reach new customers.\" Although competition in the industry is intense, Taylor said that Google is dedicated to helping its publisher and advertisement partners succeed.\\n\\nRead Also: Google Delays EU Rollout of Bard AI Chatbot-Here\\'s Why\\n\\nProbe Whether Google Favored Its Own Online Display Ads', metadata={'url': 'http://www.hngn.com/articles/249493/20230614/google-forced-split-ad-tech-division-due-eu-antitrust-charges.htm', 'GoldsteinScale': '3.0', 'AvgTone': '-2.35756385068762', 'source': 'http://www.hngn.com/articles/249493/20230614/google-forced-split-ad-tech-division-due-eu-antitrust-charges.htm', 'publish_date': '2023-06-14 00:00:00', 'language': 'en', 'Actor1Name': 'RUSSIA', 'NumArticles': '10', 'summary': \"European Union (EU) antitrust officials made a groundbreaking ruling on Wednesday, June 14, by suggesting the internet giant Google sell off a portion of its profitable digital advertising business due to competition concerns.\\nNow that the commission has given Google the opportunity to respond, it may present its case in defense.\\nAlthough competition in the industry is intense, Taylor said that Google is dedicated to helping its publisher and advertisement partners succeed.\\nEC Vice President Margrethe Vestager said Google dominates both the buying and selling sides of the advertising business.\\nIn addition to these investigations in the EU, Google's ad tech company is being scrutinized in the UK and the US.\", 'date': '20230614', 'title': 'Google May Be Forced to Split Ad-Tech Division Due to EU Antitrust Charges', 'Actor2Name': 'GOOGLE', 'NumMentions': '[10]', 'NumSources': '1'}),\n",
       " Document(page_content='The experiences evoke AI-powered search rivals like You.com and Perplexity AI. But Rany Ng, VP of Search, argues that they uniquely benefit from Google’s proprietary data, including details on more than 200 million places in the world and 35 billion product listings.\\n\\n“With this improved experience in SGE, you’ll get useful insights to guide you along the way, so you can spend less time planning and more time enjoying the plans you’ve made,” Ng wrote in a blog post this morning. “And if you need to buy something that requires extensive research ahead of your summer travels, generative AI in Search can be particularly useful.”\\n\\nIn a related announcement, Google’s soon launching a new Add to Sheets experiment that’ll allow users to insert a search result directly into a spreadsheet and share it with friends, family or anyone else they might be collaborating with.', metadata={'NumArticles': '0', 'publish_date': '2023-06-14 00:00:00+00:00', 'title': 'Google intros new AI-powered travel and product search features', 'source': 'https://techcrunch.com/2023/06/14/google-intros-new-ai-powered-travel-and-product-search-features/', 'url': 'https://techcrunch.com/2023/06/14/google-intros-new-ai-powered-travel-and-product-search-features/', 'NumSources': '0', 'summary': 'Google’s new AI-powered search experience, released in May, might have gotten a mixed reception.\\nGoogle today announced new capabilities, some of which it previously previewed at its I/O conference, heading to Search Generative Experience (SGE) — the moniker for its experimental search experience — focused on travel and shopping.\\nNow, when a user asks questions about a place or destination in Google Search (e.g.\\nAnd when they’re shopping for a product — Bluetooth speakers, say — SGE will show factors to consider along with product descriptions, reviews, ratings, prices, images and recommendations.\\nTo take advantage of any of the new features, you’ll have to be enrolled in Search Labs, Google’s proving ground for new search-related technologies.', 'AvgTone': '0.0'})]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test whether search from vector store is working\n",
    "# me.similarity_search(\"What are some good black friday deals?\", k=2) # retail\n",
    "me.similarity_search(f\"What are some of {ACTOR_NAME}s recent board appointments?\", k=2) # coporate board appts - industry agnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "512e7e28-f06a-4b3a-b2c4-32c63eff9674",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Embedding query What are some of googles recent acquisitons?.\n",
      "INFO:root:Deployed Index ID = vectorstore_ggl_v1_20230614201535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(page_content='text: Google’s new AI-powered search experience, released in May, might have gotten a mixed reception. But the search giant isn’t letting that slow its feature roadmap.\\n\\nGoogle today announced new capabilities, some of which it previously previewed at its I/O conference, heading to Search Generative Experience (SGE) — the moniker for its experimental search experience — focused on travel and shopping.\\n\\nNow, when a user asks questions about a place or destination in Google Search (e.g. “Is this restaurant good for large groups?”), they’ll see a snapshot that brings together information from across the web as well as reviews, photos and business profile details submitted by business owners. And when they’re shopping for a product — Bluetooth speakers, say — SGE will show factors to consider along with product descriptions, reviews, ratings, prices, images and recommendations.', metadata={'source': 'https://techcrunch.com/2023/06/14/google-intros-new-ai-powered-travel-and-product-search-features/', 'url': 'https://techcrunch.com/2023/06/14/google-intros-new-ai-powered-travel-and-product-search-features/', 'NumSources': '0', 'NumArticles': '0', 'AvgTone': '0.0', 'title': 'Google intros new AI-powered travel and product search features', 'publish_date': '2023-06-14 00:00:00+00:00', 'summary': 'Google’s new AI-powered search experience, released in May, might have gotten a mixed reception.\\nGoogle today announced new capabilities, some of which it previously previewed at its I/O conference, heading to Search Generative Experience (SGE) — the moniker for its experimental search experience — focused on travel and shopping.\\nNow, when a user asks questions about a place or destination in Google Search (e.g.\\nAnd when they’re shopping for a product — Bluetooth speakers, say — SGE will show factors to consider along with product descriptions, reviews, ratings, prices, images and recommendations.\\nTo take advantage of any of the new features, you’ll have to be enrolled in Search Labs, Google’s proving ground for new search-related technologies.'}),\n",
       " Document(page_content='Following the settlement, Google will change its frequently asked questions (FAQs) and key terms pages to explain the circumstances under which search queries are shared with third parties using referrer headers.\\n\\nMore on Google lawsuits:40 states settle Google location-tracking charges for $392M', metadata={'summary': 'People who searched using Google and clicked on search results between October 2006 and September 2013 may be entitled to receive a cut of a $23 million settlement Google has agreed to pay.\\nPeople who used Google Search and clicked on a search result link between or on Oct. 26, 2006 and Sept. 30, 2013 are included in the settlement as a settlement class member.\\nSettlement class members have to decide to participate by July 31.\\nTo opt out the settlement, click on the Exclusion Form page, where you will register to receive a Class Member ID.\\nFollowing the settlement, Google will change its frequently asked questions (FAQs) and key terms pages to explain the circumstances under which search queries are shared with third parties using referrer headers.', 'AvgTone': '0.0', 'publish_date': '2023-06-13 00:00:00+00:00', 'url': 'https://www.cincinnati.com/story/money/2023/06/13/google-settlement-search-payout/70318406007/', 'NumArticles': '0', 'title': 'Google Search agrees to pay $23 million settlement and you may be entitled to a portion', 'NumSources': '0', 'source': 'https://www.cincinnati.com/story/money/2023/06/13/google-settlement-search-payout/70318406007/'})]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# me.similarity_search(\"What are some popular DIY projects?\", k=2) # retail - home improvement\n",
    "me.similarity_search(f\"What are some of {ACTOR_NAME}s recent acquisitons?\", k=2) # M&A activity - industry agnostic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab79d4f-f3b8-4f65-ac3e-db535cf4d2db",
   "metadata": {},
   "source": [
    "### Action Agent with VectorStore\n",
    "So, how do we move beyond basic semantic search and use a conversational agent to interact with this data?\n",
    "\n",
    "Here, we will use the PaLM LLM with a langchain agent that has access to the Vector Store to answer questions.\n",
    "\n",
    "We'll use the agent LLM that accepts a Stopword to help prevent hallucinations\n",
    "\n",
    "Make sure your REQUESTS_PER_MINUTE does not exceed the project quota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23449fc4-69ee-4d77-ac63-3a2065617cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUESTS_PER_MINUTE = 200 # project quota==300\n",
    "vertex_embedding = VertexEmbeddings(requests_per_minute=REQUESTS_PER_MINUTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6c3b75",
   "metadata": {},
   "source": [
    "Instantiate the LLM to be used with the agent - the stopword here can help decrease hallucination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "567d4ce0-1125-4d56-af6e-cdeb4d09f9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain_llm = VertexLLM(\n",
    "    stop=['Observation:']\n",
    "    , temperature=0.0\n",
    "    , max_output_tokens=1000\n",
    "    , top_p=0.7\n",
    "    , top_k=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bd8aaf",
   "metadata": {},
   "source": [
    "Create the agent with the LLM and the Vector Store \n",
    "\n",
    "**Providing descriptive Vector Store Name and Vector Store Descriptions can improve the quality of the results returned by the agent!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f7308551-3795-4c05-a1aa-8eb1074f2b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VECTOR_STORE_NAME        = news on google\n",
      "VECTOR_STORE_DESCRIPTION  = a vectorstore containing news and event documents on google from the GDELT 2.0 dataset\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents.agent_toolkits import (\n",
    "    create_vectorstore_agent,\n",
    "    VectorStoreToolkit,\n",
    "    VectorStoreInfo\n",
    ")\n",
    "\n",
    "VECTOR_STORE_NAME = f\"news on {ACTOR_NAME}\"\n",
    "VECTOR_STORE_DESCRIPTION = f\"a vectorstore containing news and event documents on {ACTOR_NAME} from the GDELT 2.0 dataset\"\n",
    "\n",
    "print(f\"VECTOR_STORE_NAME        = {VECTOR_STORE_NAME}\")\n",
    "print(f\"VECTOR_STORE_DESCRIPTION  = {VECTOR_STORE_DESCRIPTION}\")\n",
    "\n",
    "\n",
    "vectorstore_info = VectorStoreInfo(\n",
    "    name = f\"{VECTOR_STORE_NAME}\"\n",
    "    , description=f\"{VECTOR_STORE_DESCRIPTION}\"\n",
    "    , vectorstore=me                          ,\n",
    ")\n",
    "\n",
    "toolkit = VectorStoreToolkit(vectorstore_info=vectorstore_info, llm=langchain_llm)\n",
    "\n",
    "agent_executor = create_vectorstore_agent(\n",
    "    llm=langchain_llm,\n",
    "    toolkit=toolkit,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "index = VectorStoreIndexWrapper(vectorstore=me)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880c2b57",
   "metadata": {},
   "source": [
    "Verify your toolkit\n",
    "\n",
    "Example output:\n",
    "\n",
    "```\n",
    "VectorStoreToolkit(vectorstore_info=VectorStoreInfo(vectorstore=<zeitghost.vertex.MatchingEngineVectorstore.MatchingEngineVectorStore object at 0x7fc36431a1f0>, name='news on google', description='a vectorstore containing news and event documents on google from the GDELT 2.0 dataset'), llm=VertexLLM(cache=None, verbose=False, callbacks=None, callback_manager=None, model=<vertexai.language_models._language_models.TextGenerationModel object at 0x7fc364015880>, predict_kwargs={'temperature': 0.0, 'max_output_tokens': 1000, 'top_p': 0.7, 'top_k': 10}, model_source='text-bison@001', stop=['Observation:'], strip=False, strip_chars=['{', '}', '\\n']))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cdd616b0-ebda-4db9-93bf-47230f270697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreToolkit(vectorstore_info=VectorStoreInfo(vectorstore=<zeitghost.vertex.MatchingEngineVectorstore.MatchingEngineVectorStore object at 0x7fc36431a1f0>, name='news on google', description='a vectorstore containing news and event documents on google from the GDELT 2.0 dataset'), llm=VertexLLM(cache=None, verbose=False, callbacks=None, callback_manager=None, model=<vertexai.language_models._language_models.TextGenerationModel object at 0x7fc364015880>, predict_kwargs={'temperature': 0.0, 'max_output_tokens': 1000, 'top_p': 0.7, 'top_k': 10}, model_source='text-bison@001', stop=['Observation:'], strip=False, strip_chars=['{', '}', '\\n']))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f2dbc4-52a0-4d95-abf1-8188e8385997",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Use the langchain `VectorStoreAgent`\n",
    "\n",
    "Note: we are using the langchain llm that has a stopword `Observation:` to prevent halllucations\n",
    "\n",
    "For experimentation purposes, we have also noticed that running\n",
    "\n",
    "`agent_executor(query)` instead of `agent_executor.run(query)` can provide helpful insight into the reasoning process of the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e4a0730a-449b-427e-8a9c-859423255045",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Embedding query What are the top news stories for google?\n",
      ".\n",
      "INFO:root:Deployed Index ID = vectorstore_ggl_v1_20230614201535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mI need to use the news on google tool to answer this question\n",
      "Action: news on google\n",
      "Action Input: What are the top news stories for google?\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mrules by the European Commission.\n",
      "\n",
      "The EU's antitrust chief, Margrethe Vestager, said in a statement that Google is \"abusing its dominant position in the online advertising market.\"\n",
      "\n",
      "\"Google is present at almost every level of the so-called ad tech supply chain,\" Vestager said. \"Our first concern is that Google is using its market position to favor its own intermediary services.\"\n",
      "\n",
      "The commission said that Google's practices have led to higher prices for advertisers and less choice for consumers.\n",
      "\n",
      "Google has been accused of using its dominance in the online advertising market to favor its own services, such as AdSense and AdMob. The company has also been accused of making it difficult for advertisers to use other advertising platforms.\n",
      "\n",
      "Google has denied the allegations, saying that it has \"always worked hard to comply with the law.\"\n",
      "\n",
      "The commission has not yet announced what penalties it will impose on Google. However, the company could face a fine of up to 10% of its global revenue.\n",
      "\n",
      "Google is not the only tech company to be accused of violating EU antitrust rules. In recent years, the commission has also taken action against Apple, Amazon, and Facebook.\n",
      "\n",
      "The EU's antitrust rules are designed to prevent companies from abusing their market power. The commission has the power to fine companies that violate the rules, and it can also order them to change their business practices.\n",
      "\n",
      "The EU's antitrust rules are important because they help to ensure that competition is fair and that consumers have a choice of products and services.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: Google is being investigated by the European Commission for violating antitrust\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Google is being investigated by the European Commission for violating antitrust'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = f\"Use [{VECTOR_STORE_NAME}]: \" + \\\n",
    "        f\"What are the top news stories for {ACTOR_NAME}?\"\n",
    "\n",
    "# print(query)\n",
    "agent_executor.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dde8c6f0-9453-4b78-ae61-9bef0a2b21ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = f\"Use [{VECTOR_STORE_NAME}]: \" + \\\n",
    "        f\"How does {ACTOR_NAME}'s commitment to technology impact their brand perception?\"\n",
    "\n",
    "print(query)\n",
    "agent_executor.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cab45bf9-b8e9-44c7-9888-675b7fbe8943",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = f\"Use [{VECTOR_STORE_NAME}]: \" + \\\n",
    "        f\"What are some of {ACTOR_NAME}'s most popular brands\"\n",
    "\n",
    "print(query)\n",
    "agent_executor.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "299a1eb3-5ca6-4d51-b4e2-8cfa42e26a49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = f\"Use [{VECTOR_STORE_NAME}]: \" + \\\n",
    "        f\"How is {ACTOR_NAME} impacted by economic uncertainty?\"\n",
    "\n",
    "print(query)\n",
    "agent_executor.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd0b04eb-2426-4a20-a004-5f08475d67cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = f\"Use [{VECTOR_STORE_NAME}]: \" + \\\n",
    "        f\"What will the impact of inflation have on the {ACTOR_CATEGORY} category over the next 6 months?\"\n",
    "\n",
    "print(query)\n",
    "agent_executor.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fcc4ff96-4cec-47fb-a618-be047229b7de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = f\"Use [{VECTOR_STORE_NAME}]: \" + \\\n",
    "        f\"What are the most popular TikTok trends for {ACTOR_CATEGORY} from the last 6 months?\"\n",
    "\n",
    "print(query)\n",
    "agent_executor.run(query)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m108"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
