{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2805f6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8876072e-dd8b-4163-976b-379a3e032138",
   "metadata": {},
   "source": [
    "# Build Zeitghost Custom Container Image for MLOps \n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/language/intro_palm_api.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/intro_palm_api.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/blob/main/language/intro_palm_api.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba15ba91-f27b-483b-97e7-f3992b116090",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "<center>\n",
    "<img src=\"imgs/zghost_overview_pipeline_steps.png\" width=\"1200\"/>\n",
    "</center>\n",
    "\n",
    "Vertex Pipelines are effectively running containerized executions for each step (component) in the pipeline workflow. To simplify and reduce container creation overhead, we've included this notebook so that you can create a single custom container image that can be used for the pipeline in notebook 05-gdelt-pipelines. \n",
    "\n",
    "Whilst you don't necessarily have to use a custom container, the alternative is to use a base container image and pass a list of packages required to run each component step in the pipeline definition.\n",
    "\n",
    "The previous notebooks:\n",
    "\n",
    "1. [Setup Vertex Vector Store](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/intro_palm_api.ipynb)\n",
    "2. [GDELT DataOps](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/intro_palm_api.ipynb)\n",
    "3. [Vector Store Index Loader](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/intro_palm_api.ipynb)\n",
    "4. [Alternative document format embeddings](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/intro_palm_api.ipynb)\n",
    "\n",
    "Have shown how you can perform a one-off extraction, index, and load into the Matching Engine Vector Store and how you can use a Langchain Agent to query the Vector Store using natural language queries. \n",
    "\n",
    "However, given the nature of GDELT data it may become critical to orchestrate and schedule a regularly occuring update of the Index with new vectors, as new GDELT entity and event data becomes available for a given topic or actor. \n",
    "\n",
    "To address this challenge, we've created a Vertex AI pipeline which will modularize, orchestrate, and only update the existing Matching Engine Index with new vectors when new data is extracted - the [GDELT Pipelines](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/intro_palm_api.ipynb) notebook shows how to create this pipeline. \n",
    "\n",
    "In order to create this pipeline, you'll need to containerize the environment dependencies for all of these differnet components to run - to streamline this process, you can use this notebook to generate the container to use with the pipeline. \n",
    "\n",
    "If your environment changes and you're extending your application, we also show how you can create a [Cloud Build Trigger](https://cloud.google.com/build/docs/automating-builds/create-manage-triggers) to automatically rebuild this container image each time new code changes are pushed to your `main` branch.\n",
    "\n",
    "---\n",
    "\n",
    "### Objectives\n",
    "\n",
    "In this notebook, the steps performed include:\n",
    "\n",
    "- Create a `Dockerfile_gdelt` image to use with Vertex AI Pipelines components\n",
    "- Choose to build the custom container image either:\n",
    "    - Locally with `Docker`\n",
    "    - Using Cloud services with [Cloud Build](https://cloud.google.com/build/docs)\n",
    "- Cloud Build [trigger](https://cloud.google.com/build/docs/automating-builds/create-manage-triggers) setup to rebuild image each time pushed to `main` branch and tag with `latest`\n",
    "- The built image will be used as the base image in pipeline steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac39bc3c",
   "metadata": {},
   "source": [
    "### Costs\n",
    "This tutorial uses billable components of Google Cloud:\n",
    "\n",
    "* Cloud Build\n",
    "* Artifact Registry\n",
    "\n",
    "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing),\n",
    "and use the [Pricing Calculator](https://cloud.google.com/products/calculator/)\n",
    "to generate a cost estimate based on your projected usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616daaac",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "**Colab only:** Uncomment the following cell to restart the kernel. For Vertex AI Workbench you can restart the terminal using the button on top. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2b2965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Automatically restart kernel after installs so that your environment can access the new packages\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1146ba",
   "metadata": {},
   "source": [
    "### Authenticating your notebook environment\n",
    "* If you are using **Colab** to run this notebook, uncomment the cell below and continue.\n",
    "* If you are using **Vertex AI Workbench**, check out the setup instructions [here](https://github.com/GoogleCloudPlatform/generative-ai/tree/main/setup-env)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5698351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aec147c-a503-4150-be6a-2d540628f24e",
   "metadata": {},
   "source": [
    "### Make sure you edit the values below\n",
    "Each time you run the notebook for the first time with new variables, you just need to edit the actor prefix and version variables below. They are needed to grab all the other variables in the notebook configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfce248a-752c-495c-bf85-94ef15140c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE_NEW_ASSETS        = True # True | False\n",
    "ACTOR_PREFIX             = \"way\"\n",
    "VERSION                  = 'v1'\n",
    "\n",
    "# print(f\"CREATE_NEW_ASSETS  : {CREATE_NEW_ASSETS}\")\n",
    "print(f\"ACTOR_PREFIX       : {ACTOR_PREFIX}\")\n",
    "print(f\"VERSION            : {VERSION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ef6a24-5506-49f6-83f1-79b468a23828",
   "metadata": {},
   "source": [
    "### Load configuration settings from setup notebook\n",
    "> Set the constants used in this notebook and load the config settings from the `00-env-setup.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001a41a4-486c-4db5-8760-8b4a8b798912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "BUCKET_NAME              = f'zghost-{ACTOR_PREFIX}-{VERSION}-{PROJECT_ID}'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)\n",
    "\n",
    "print(f\"BUCKET_NAME        : {BUCKET_NAME}\")\n",
    "print(f\"BUCKET_URI         : {BUCKET_URI}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4372c07-afd4-4918-bfd7-0b08c0897a8b",
   "metadata": {},
   "source": [
    "### Container Image Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f70dc9-5af6-4d82-b718-2b8b6b1e57d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "root_path = '..'\n",
    "os.chdir(root_path)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55997d0c-7c92-4b39-91a5-8b1914fb864b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCKERNAME                = f'Dockerfile_gdelt'\n",
    "\n",
    "REPOSITORY                = f'zghost-{ACTOR_PREFIX}'\n",
    "IMAGE_NAME                = f'gdelt-pipe-{VERSION}'\n",
    "\n",
    "REMOTE_IMAGE_NAME         = f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{REPOSITORY}/{IMAGE_NAME}\"\n",
    "\n",
    "print(f\"DOCKERNAME        = {DOCKERNAME}\")\n",
    "print(f\"REPOSITORY        = {REPOSITORY}\")\n",
    "print(f\"IMAGE_NAME        = {IMAGE_NAME}\")\n",
    "print(f\"REMOTE_IMAGE_NAME = {REMOTE_IMAGE_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2effdda2-8fb3-4cab-9018-e834b6441581",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create Artifact Repository\n",
    "If you don't have an existing artifact repository, create one using the gcloud command below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc261485-a773-4e20-9a01-1a42a7c41de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "! gcloud artifacts repositories create $REPOSITORY --repository-format=docker --location=$LOCATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde1b0a5-9751-43a1-9c65-3f89bb863e03",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Local Docker build\n",
    "Provide a name for your dockerfile and make sure you are authenticated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a77e762-39e6-48fb-a899-935d97c39e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "! gcloud auth configure-docker $REGION-docker.pkg.dev --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441c6bd6",
   "metadata": {},
   "source": [
    "Create your Dockerfile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5e5a86-5cb7-45c8-8b71-e3a4b80149ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {DOCKERNAME}\n",
    "\n",
    "FROM python:3.10\n",
    "\n",
    "ENV PYTHONUNBUFFERED True\n",
    "\n",
    "ENV APP_HOME /workspace\n",
    "\n",
    "WORKDIR $APP_HOME\n",
    "\n",
    "COPY notebooks/requirements.txt $APP_HOME/requirements.txt\n",
    "\n",
    "RUN pip install --upgrade pip\n",
    "RUN pip install --no-cache-dir -r $APP_HOME/requirements.txt\n",
    "\n",
    "ADD zeitghost $APP_HOME/zeitghost\n",
    "\n",
    "RUN ls zeitghost\n",
    "\n",
    "RUN export PYTHONPATH=${PYTHONPATH}:${APP_HOME}/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcad2224-3259-4411-8a1e-d49310487080",
   "metadata": {},
   "source": [
    "### Build Image Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef7aba9-fce8-4e4c-ac4d-b9a402ac500e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!docker build -t $REMOTE_IMAGE_NAME -f $DOCKERNAME ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed11094d",
   "metadata": {},
   "source": [
    "Once your container has finished building, now push it to the GCP Artifact Registry - once it's pushed, it can be used in the pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebaeca8-028a-4fa1-88e5-2fe73539ce50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### push the container to registry\n",
    "!docker push $REMOTE_IMAGE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af33ee3-229f-41bf-848b-4cb346d40b73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m108"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
