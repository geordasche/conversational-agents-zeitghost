{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e5cd0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d76b97c-f1a8-4532-9c4a-8bfe920d86bf",
   "metadata": {},
   "source": [
    "# Extract data from GDELT - a global database of society (news, events, entities, wikipedia) \n",
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/language/intro_palm_api.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/intro_palm_api.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/blob/main/language/intro_palm_api.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898626f4",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "<center>\n",
    "<img src=\"imgs/zghost_overview_gdelt.png\" width=\"1200\"/>\n",
    "</center>\n",
    "\n",
    "In the initial environment set up notebook you sampled a bit of the GDELT data (and perhaps experimented with different actor names, different time ranges). Now, we will run a full extraction of your actor_name and selected time range of the data the GDELT by downloading the full content of the media articles from the URLs provided by GDELT.\n",
    "\n",
    "**Depending on how often your actor_name appears in the news and on the time range, the article content extraction steps may take anywhere from a few minutes to a few hours - it depends on what you are trying to extract! Our recommendation is to start small, you can always add more data later to the existing Matching Engine Index.**\n",
    "\n",
    "Finally, the 05-gdelt-pipelines notebook will show you how to scale this job in a managed pipeline that can be scheduled to run on an ongoing basis. \n",
    "\n",
    "---\n",
    "\n",
    "### GDELT\n",
    "Supported by Google Jigsaw, the [GDELT Project](https://www.gdeltproject.org/) monitors the world's broadcast, print, and web news from nearly every corner of every country in over 100 languages and identifies the people, locations, organizations, themes, sources, emotions, counts, quotes, images and events driving our global society every second of every day, creating a free open platform for computing on the entire world.\n",
    "\n",
    "<i>\"The GDELT Project is an initiative to construct a catalog of human societal-scale behavior and beliefs across all countries of the world, connecting every person, organization, location, count, theme, news source, and event across the planet into a single massive network that captures what's happening around the world, what its context is and who's involved, and how the world is feeling about it, every single day.\"</i>\n",
    "\n",
    "Monitoring nearly the entire world's news media is only the beginning - even the largest team of humans could not begin to read and analyze the billions upon billions of words and images published each day. GDELT uses some of the world's most sophisticated computer algorithms, custom-designed for global news media, running on \"one of the most powerful server networks in the known Universe\", together with some of the world's most powerful deep learning algorithms, to create a realtime computable record of global society that can be visualized, analyzed, modeled, examined and even forecasted. A huge array of datasets totaling trillions of datapoints are available. Three primary data streams are created, one codifying physical activities around the world in over 300 categories, one recording the people, places, organizations, millions of themes and thousands of emotions underlying those events and their interconnections and one codifying the visual narratives of the world's news imagery.\n",
    "\n",
    "All three streams update every 15 minutes, offering near-realtime insights into the world around us. Underlying the streams are a vast array of sources, from hundreds of thousands of global media outlets to special collections like 215 years of digitized books, 21 billion words of academic literature spanning 70 years, human rights archives and even saturation processing of the raw closed captioning stream of almost 100 television stations across the US in collaboration with the Internet Archive's Television News Archive. Finally, also in collaboration with the Internet Archive, the Archive captures nearly all worldwide online news coverage monitored by GDELT each day into its permanent archive to ensure its availability for future generations even in the face of repressive forces that continue to erode press freedoms around the world.\n",
    "\n",
    "Detailed GDELT documentation links for various datasets and source formats can be found [here](https://www.gdeltproject.org/data.html) (scroll down to documentation). See the [GCAM Master Codebook](http://data.gdeltproject.org/documentation/GCAM-MASTER-CODEBOOK.TXT) for a list of all of the dimensions available and the [Global Knowledge Graph 2.0 Codebook](http://data.gdeltproject.org/documentation/GDELT-Global_Knowledge_Graph_Codebook-V2.pdf) (scroll down to the GCAM field) for more details on the file format of the GCAM field and how to work with it.\n",
    "\n",
    "In these notebooks, we will focus on the GDELT Global Knowledge Graph dataset, publicly available for anyone to use in [Google BigQuery](https://www.gdeltproject.org/data.html). \n",
    "\n",
    "From the very beginning, one of the greatest challenges in working with GDELT has been in how to interact with a dataset of this magnitude. Few database platforms can handle a dataset this complex with the sheer variety of access patterns and the number of permutations of fields that are collected together into queries each day.\n",
    "\n",
    "Google's BigQuery database was custom-designed for datasets like GDELT, enabling near-realtime adhoc querying over the entire dataset. This means that no matter how you access GDELT, what columns you look across, what kinds of operators you use, or the complexity of your query, you will still see results pretty much in near-realtime.\n",
    "\n",
    "For us, the most groundbreaking part of having GDELT in BigQuery is that it opens the door not only to fast complex querying and extracting of data, but also allows for the first time real-world analyses to be run entirely in the database.\n",
    "\n",
    "Imagine computing the most significant conflict interaction in the world by month over the past 35 years, or performing cross-tabbed correlation over different classes of relationships between a set of countries. Such queries can be run entirely inside of BigQuery and return in just a handful of seconds. This enables you to try out \"what if\" hypotheses on global-scale trends in near-real time. We'll also show how you can orchestrated and schedule ongoing data updates from the dataset to ensure your data stays up to date with the required latency. \n",
    "\n",
    "\n",
    "### Objectives\n",
    "\n",
    "In this notebook, you will \n",
    "\n",
    "The steps performed include:\n",
    "\n",
    "- GDELT Event Data \n",
    "    - Specify the parameters of interest (topic(s), time)\n",
    "    - Run the extraction process, generate full article content\n",
    "    - Load and label this data back into BigQuery destination tables\n",
    "- GDELT Entity Graph Data \n",
    "    - Specify the parameters of interest (actor(s), time)\n",
    "    - Run the extraction process, generate full article content\n",
    "    - Load and label this data back into BigQuery destination tables\n",
    "\n",
    "After you have run this notebook, you may want to set up a recurring schedule for extraction of the GDELT data - the [GDELT Pipelines Notebook]() shows how to create an end to end pipeline including updating the Matching Engine Vector store with the latest GDELT data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548fbc4d",
   "metadata": {},
   "source": [
    "### Costs\n",
    "This tutorial uses billable components of Google Cloud:\n",
    "\n",
    "* Vertex AI Generative AI Studio\n",
    "* BigQuery Storage & BigQuery Compute\n",
    "* Google Cloud Storage\n",
    "\n",
    "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing),\n",
    "and use the [Pricing Calculator](https://cloud.google.com/products/calculator/)\n",
    "to generate a cost estimate based on your projected usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c60437",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "**Colab only:** Uncomment the following cell to restart the kernel. For Vertex AI Workbench you can restart the terminal using the button on top. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "379152ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Automatically restart kernel after installs so that your environment can access the new packages\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95913ca",
   "metadata": {},
   "source": [
    "### Authenticating your notebook environment\n",
    "* If you are using **Colab** to run this notebook, uncomment the cell below and continue.\n",
    "* If you are using **Vertex AI Workbench**, check out the setup instructions [here](https://github.com/GoogleCloudPlatform/generative-ai/tree/main/setup-env)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b06aae29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46007d01-858d-4184-877a-3c02fe7eea25",
   "metadata": {},
   "source": [
    "### Make sure you edit the values below\n",
    "Each time you run the notebook for the first time with new variables, you just need to edit the actor prefix and version variables below. They are needed to grab all the other variables in the notebook configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d209bb4-8720-4f07-a3f7-07c659a2446b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTOR_PREFIX       : ggl\n",
      "VERSION            : v1\n"
     ]
    }
   ],
   "source": [
    "# CREATE_NEW_ASSETS        = True # True | False\n",
    "ACTOR_PREFIX             = \"ggl\"\n",
    "VERSION                  = 'v1'\n",
    "\n",
    "# print(f\"CREATE_NEW_ASSETS  : {CREATE_NEW_ASSETS}\")\n",
    "print(f\"ACTOR_PREFIX       : {ACTOR_PREFIX}\")\n",
    "print(f\"VERSION            : {VERSION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7981cc-16e4-41d5-b216-31928b82f745",
   "metadata": {},
   "source": [
    "### Load configuration settings from setup notebook\n",
    "Set the constants used in this notebook and load the config settings from the `00-env-setup.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6367758-765e-440d-95e6-9d52f0449a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PROJECT_ID               = \"wortz-project-352116\"\n",
      "PROJECT_NUM              = \"679926387543\"\n",
      "LOCATION                 = \"us-central1\"\n",
      "\n",
      "REGION                   = \"us-central1\"\n",
      "BQ_LOCATION              = \"US\"\n",
      "VPC_NETWORK_NAME         = \"me-network\"\n",
      "\n",
      "CREATE_NEW_ASSETS        = \"True\"\n",
      "ACTOR_PREFIX             = \"ggl\"\n",
      "VERSION                  = \"v1\"\n",
      "ACTOR_NAME               = \"google\"\n",
      "ACTOR_CATEGORY           = \"technology\"\n",
      "\n",
      "BUCKET_NAME              = \"zghost-ggl-v1-wortz-project-352116\"\n",
      "EMBEDDING_DIR_BUCKET     = \"zghost-ggl-v1-wortz-project-352116-emd-dir\"\n",
      "\n",
      "BUCKET_URI               = \"gs://zghost-ggl-v1-wortz-project-352116\"\n",
      "EMBEDDING_DIR_BUCKET_URI = \"gs://zghost-ggl-v1-wortz-project-352116-emd-dir\"\n",
      "\n",
      "VPC_NETWORK_FULL         = \"projects/679926387543/global/networks/me-network\"\n",
      "\n",
      "ME_INDEX_NAME            = \"vectorstore_ggl_v1\"\n",
      "ME_INDEX_ENDPOINT_NAME   = \"vectorstore_ggl_v1_endpoint\"\n",
      "ME_DIMENSIONS            = \"768\"\n",
      "\n",
      "MY_BQ_DATASET            = \"zghost_ggl_v1\"\n",
      "MY_BQ_TRENDS_DATASET     = \"zghost_ggl_v1_trends\"\n",
      "\n",
      "BUCKET_NAME        : zghost-ggl-v1-wortz-project-352116\n",
      "BUCKET_URI         : gs://zghost-ggl-v1-wortz-project-352116\n"
     ]
    }
   ],
   "source": [
    "# staging GCS\n",
    "GCP_PROJECTS             = !gcloud config get-value project\n",
    "PROJECT_ID               = GCP_PROJECTS[0]\n",
    "\n",
    "BUCKET_NAME              = f'zghost-{ACTOR_PREFIX}-{VERSION}-{PROJECT_ID}'\n",
    "BUCKET_URI               = f'gs://{BUCKET_NAME}'\n",
    "\n",
    "config = !gsutil cat {BUCKET_URI}/config/notebook_env.py\n",
    "print(config.n)\n",
    "exec(config.n)\n",
    "\n",
    "print(f\"BUCKET_NAME        : {BUCKET_NAME}\")\n",
    "print(f\"BUCKET_URI         : {BUCKET_URI}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead938c3-5b7d-4af1-af46-d8737997c17a",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11fccf33-2adc-4f1d-9175-22c7ed52bfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform as vertex_ai\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# the langchain document loaders for loading data from different sources\n",
    "# from langchain.document_loaders import DataFrameLoader #TODO REMOVE\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import io\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from IPython.display import display, Image, Markdown\n",
    "from PIL import Image, ImageDraw\n",
    "import logging\n",
    "logging.basicConfig(level = logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655dc995-4c4e-408b-a88f-f19b114f8ee1",
   "metadata": {},
   "source": [
    "Instantiate Google Cloud SDK clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9e07479-1c28-4722-86d1-25b4fd60df63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloud storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "# Vertex client\n",
    "vertex_ai.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "# bigquery client\n",
    "bqclient = bigquery.Client(\n",
    "    project=PROJECT_ID,\n",
    "    # location=LOCATION\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2276cd4-08dd-4fc2-a1cc-ba2fe5e903e4",
   "metadata": {},
   "source": [
    "# Getting started with the GDELT data\n",
    "First import the GDELT data helper classes from Zeitghost.gdelt.GdeltData which perform the following tasks:\n",
    "- Extracts the relevant GDELT data of interest for the time period and actor specified and loads this into a BQ table\n",
    "- Processes the articles for use\n",
    "    -  Given a Gdelt record: group articles by domain, download domain level information.\n",
    "    - For each article: download articles, parse downloaded information, and do simple nlp summarization\n",
    "- Write the extracted output information to a Cloud Storage Bucket\n",
    "- Write to final BQ destination tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4598108d-2b58-451e-a93b-cdecca8a572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "from zeitghost.gdelt.GdeltData import GdeltData\n",
    "from zeitghost.bigquery.BigQueryAccessor import BigQueryAccessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a39c99",
   "metadata": {},
   "source": [
    "## GDELT Event Data\n",
    "\n",
    "Here we will grab a \"small\" subset of records from the GDELT `events` and `global entity graph (geg)` tables. The goal here is to become familiar with each table, so depending on the amount of available news concerning your actor you'll want to keep the time window between the `min_date` and `max_date` parameters relatively small. Later we will increase this time window when we orchestrate these steps in a Vertex AI Managed Pipeline  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8401b0-6c8c-4793-af07-bef2f075bc50",
   "metadata": {},
   "source": [
    "### Define Events & Time Period"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611798b5-edf7-49ee-a6d3-df88a8615f35",
   "metadata": {},
   "source": [
    "Find relevant events from [GDELT 2.0](https://blog.gdeltproject.org/gdelt-2-0-our-global-world-in-realtime/)\n",
    "\n",
    "> GDELT 2.0 is poised to redefine how we understand and interact with our global world, transcending language barriers and reaching deeply into the reactions and emotional resonance of world events\n",
    "\n",
    "* realtime translation of the world’s news in 65 languages\n",
    "* measurement of more than 2,300 emotions and themes from every article\n",
    "* massive inventory of the media of the non-Western world"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8eb8979-02b2-4588-ac1d-1ee68926d90f",
   "metadata": {},
   "source": [
    "### Set Variables \n",
    "\n",
    "- actor(s) of interest - STRING -  use | to separate actors\n",
    "- BigQuery destination tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5356b5e-1b1d-46c5-a675-5075ca0a98b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTOR_NAME   : google\n",
      "ACTOR_PREFIX : ggl\n",
      "MIN_DATE     : 2023-06-14\n",
      "MAX_DATE     : 2023-06-15\n"
     ]
    }
   ],
   "source": [
    "# set dates - '%Y%m%d'\n",
    "MIN_DATE = \"2023-06-14\" # TODO\n",
    "MAX_DATE = \"2023-06-15\" # TODO\n",
    "\n",
    "print(f\"ACTOR_NAME   : {ACTOR_NAME}\")\n",
    "print(f\"ACTOR_PREFIX : {ACTOR_PREFIX}\")\n",
    "print(f\"MIN_DATE     : {MIN_DATE}\")\n",
    "print(f\"MAX_DATE     : {MAX_DATE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa54d033-2597-4668-b8bb-4a5c8fc6ac45",
   "metadata": {
    "tags": []
   },
   "source": [
    "Set destination tables in BigQuery and print out the names - this is where the data will be uploaded to when it completes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1108f222-8266-468e-89ab-9101d3241911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GDELT_TABLE_NAME         : events_gdelt_ggl_v1\n",
      "GDELT_TABLE_REF          : wortz-project-352116.zghost_ggl_v1.events_gdelt_ggl_v1\n",
      "SCRAPED_GDELT_TABLE_REF  : wortz-project-352116.zghost_ggl_v1.scraped_events_gdelt_ggl_v1\n"
     ]
    }
   ],
   "source": [
    "GDELT_TABLE_NAME                 = f'events_gdelt_{ACTOR_PREFIX}_{VERSION}'\n",
    "\n",
    "GDELT_TABLE_REF                  = f'{PROJECT_ID}.{MY_BQ_DATASET}.{GDELT_TABLE_NAME}'\n",
    "SCRAPED_GDELT_TABLE_REF          = f'{PROJECT_ID}.{MY_BQ_DATASET}.scraped_{GDELT_TABLE_NAME}'\n",
    "\n",
    "print(f\"GDELT_TABLE_NAME         : {GDELT_TABLE_NAME}\")\n",
    "print(f\"GDELT_TABLE_REF          : {GDELT_TABLE_REF}\")\n",
    "print(f\"SCRAPED_GDELT_TABLE_REF  : {SCRAPED_GDELT_TABLE_REF}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f0540f-8fa8-4d90-8869-287a52f1dbbd",
   "metadata": {},
   "source": [
    "### Extract Relevant Event Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276816ba-dc01-493f-b993-d3f74fb27763",
   "metadata": {},
   "source": [
    "* Convert to `dataframe` or `BQ row iterator`\n",
    "* Load actor's raw events to BQ table\n",
    "* Use zeitghost `Gdelt` classes to scrape events article urls and write to new BQ table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c0113e-46b3-4fc1-8ada-5dc3ceff68c7",
   "metadata": {},
   "source": [
    "## GDELT Global Entity Graph (GEG) Articles\n",
    "We'll now perform a similar extraction workflow for the GDELT Entity Graph dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030e0cec-2b3a-40d1-8f6f-753c1038ef84",
   "metadata": {},
   "source": [
    "### Set Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3d3a13c-7809-4ea7-94ef-bf0862cf6bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_DATE = \"2023-06-14\"\n",
    "MAX_DATE = \"2023-06-14\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2af3dc6c-832b-426b-921d-3efc196dc6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GDELT_TABLE_NAME         : test_geg_articles_ggl_v1\n",
      "GDELT_TABLE_REF          : wortz-project-352116.zghost_ggl_v1.test_geg_articles_ggl_v1\n",
      "SCRAPED_GDELT_TABLE_REF  : wortz-project-352116.zghost_ggl_v1.scraped_test_geg_articles_ggl_v1\n"
     ]
    }
   ],
   "source": [
    "GDELT_TABLE_NAME                 = f'test_geg_articles_{ACTOR_PREFIX}_{VERSION}'\n",
    "\n",
    "GDELT_TABLE_REF                  = f'{PROJECT_ID}.{MY_BQ_DATASET}.{GDELT_TABLE_NAME}'\n",
    "SCRAPED_GDELT_TABLE_REF          = f'{PROJECT_ID}.{MY_BQ_DATASET}.scraped_{GDELT_TABLE_NAME}'\n",
    "\n",
    "print(f\"GDELT_TABLE_NAME         : {GDELT_TABLE_NAME}\")\n",
    "print(f\"GDELT_TABLE_REF          : {GDELT_TABLE_REF}\")\n",
    "print(f\"SCRAPED_GDELT_TABLE_REF  : {SCRAPED_GDELT_TABLE_REF}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04d8084-d604-48fe-94fd-1f380a082999",
   "metadata": {},
   "source": [
    "### Extract Relevant Entity Graph Articles\n",
    "We'll use the BigQueryAccessor to interact with the gdelt entity graph dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7db8271c-4612-484b-9ca2-e0bb0b83067a",
   "metadata": {},
   "outputs": [],
   "source": [
    "geg_data_accessor = BigQueryAccessor(\n",
    "    PROJECT_ID\n",
    "    , gdelt_project_id='gdelt-bq'\n",
    "    , gdelt_dataset_id='gdeltv2'\n",
    "    , gdelt_table_name='geg_gcnlapi'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c420b3ac",
   "metadata": {},
   "source": [
    "Use either the pandas dataframe or row iterator to fetch the relevant records for the actor_name and time range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e64b885d-b5f0-465d-b526-9ae552feb404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 15.410439014434814\n"
     ]
    }
   ],
   "source": [
    "# get df\n",
    "start = time.time()\n",
    "\n",
    "geg_articles_accessor = geg_data_accessor.get_geg_article_data_v2_full_df(\n",
    "    entity = ACTOR_NAME\n",
    "    , min_date = MIN_DATE\n",
    "    , max_date = MAX_DATE\n",
    ")\n",
    "\n",
    "# BQ row iterator\n",
    "# geg_articles_row_iterator = geg_data_accessor.get_geg_article_data(\n",
    "    # entity = ACTOR_NAME\n",
    "    # , min_date = MIN_DATE\n",
    "    # , max_date = MAX_DATE\n",
    "# )\n",
    "\n",
    "end = time.time()\n",
    "print(f\"elapsed time: {end - start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a94074",
   "metadata": {},
   "source": [
    "Preview the types of URLs, dates, and salience for the articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d918cf41-9520-486b-93ef-7672122183d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>avgSalience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://techcrunch.com/2023/06/14/google-lens-...</td>\n",
       "      <td>2023-06-14 17:18:05+00:00</td>\n",
       "      <td>0.326141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://techcrunch.com/2023/06/14/google-lens-...</td>\n",
       "      <td>2023-06-14 17:18:05+00:00</td>\n",
       "      <td>0.188845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.androidpolice.com/google-news-mate...</td>\n",
       "      <td>2023-06-14 18:01:57+00:00</td>\n",
       "      <td>0.197368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://cyprus-mail.com/author/malia/</td>\n",
       "      <td>2023-06-14 06:47:12+00:00</td>\n",
       "      <td>0.131228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://cyprus-mail.com/author/nikolaos/</td>\n",
       "      <td>2023-06-14 19:32:17+00:00</td>\n",
       "      <td>0.131228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://techcrunch.com/2023/06/14/google-lens-...   \n",
       "1  https://techcrunch.com/2023/06/14/google-lens-...   \n",
       "2  https://www.androidpolice.com/google-news-mate...   \n",
       "3              https://cyprus-mail.com/author/malia/   \n",
       "4           https://cyprus-mail.com/author/nikolaos/   \n",
       "\n",
       "                       date  avgSalience  \n",
       "0 2023-06-14 17:18:05+00:00     0.326141  \n",
       "1 2023-06-14 17:18:05+00:00     0.188845  \n",
       "2 2023-06-14 18:01:57+00:00     0.197368  \n",
       "3 2023-06-14 06:47:12+00:00     0.131228  \n",
       "4 2023-06-14 19:32:17+00:00     0.131228  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(geg_articles_accessor.shape)\n",
    "geg_articles_accessor.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec038be-5fa1-466e-ae5a-8efb8e31ed5f",
   "metadata": {},
   "source": [
    "Optionally, select a subsample of records to process in-notebook\n",
    "\n",
    "> indicative timing: ~20 records should process in ~60 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96c33cd7-86ca-41bd-84e7-8ac2a6c127ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 3)\n"
     ]
    }
   ],
   "source": [
    "geg_articles_accessor = geg_articles_accessor.head(20)\n",
    "print(geg_articles_accessor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b942fd9",
   "metadata": {},
   "source": [
    "Load the data to BigQuery destination tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4aca416-b858-4b7c-9cfa-d68bf71e57ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoadJob<project=wortz-project-352116, location=US, id=12e98a8e-ec30-4b49-a377-639bf2e35934>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job = bqclient.load_table_from_dataframe(\n",
    "    geg_articles_accessor\n",
    "    , GDELT_TABLE_REF\n",
    ")\n",
    "job.result()  # Wait for the job to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02ed9f3-1f76-4f1b-bc1f-fa1c68a321ed",
   "metadata": {},
   "source": [
    "Update the BigQuery table description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e81d6a17-2443-4af4-bbe1-34e4b27c3cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"articles published between `2023-06-14` to `2023-06-14` mentioning 'google' from `gdelt-bq.gdeltv2.geg_gcnlapi`\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TABLE_DESCRIPTION = f\"articles published between `{MIN_DATE}` to `{MAX_DATE}` mentioning '{ACTOR_NAME}' from `gdelt-bq.gdeltv2.geg_gcnlapi`\"\n",
    "TABLE_DESCRIPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "627aa715-df81-4c45-b006-edb7d826e123",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = bqclient.get_table(GDELT_TABLE_REF)  # API request\n",
    "table.description = f'{TABLE_DESCRIPTION}' # \"testing updated table description\"\n",
    "table = bqclient.update_table(table, [\"description\"])  # API request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b443f91-1993-46d9-9a80-e3c64b9eca02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"articles published between `2023-06-14` to `2023-06-14` mentioning 'google' from `gdelt-bq.gdeltv2.geg_gcnlapi`\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm updated description \n",
    "table.description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2ef1ad-63e2-4b15-8ff7-912d5283e76d",
   "metadata": {},
   "source": [
    "Extract the content from the relevant articles\n",
    "\n",
    "**Depending on how many articles you are extracting, this step may take anywhere from a few minutes to a few hours, we recommend to start small and add more later**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10936e41-dc60-4797-a669-2cd10cad70c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to ./...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "WARNING:newspaper.parsers:fromstring() returned an invalid string: ...\n",
      "WARNING:newspaper.source:Source https://www.androidpolice.com parse error.\n",
      "WARNING:newspaper.source:The following article urls failed the download: https://www.androidpolice.com/google-news-material-you-widgets/, https://www.androidpolice.com/google-pixel-watch-review/, https://www.androidpolice.com/big-google-home-app-update-coming/\n",
      "WARNING:newspaper.parsers:fromstring() returned an invalid string: ...\n",
      "WARNING:newspaper.source:Source https://leaderpost.com parse error.\n",
      "WARNING:newspaper.source:The following article urls failed the download: https://leaderpost.com:443/telecom/eu-regulators-order-google-to-break-up-digital-ad-business-over-competition-concerns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time: 42.79588437080383\n"
     ]
    }
   ],
   "source": [
    "from zeitghost.gdelt.GdeltData import GdeltData\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "gdelt_data_processor = GdeltData(\n",
    "    geg_articles_accessor\n",
    "    , destination_table=SCRAPED_GDELT_TABLE_REF\n",
    "    , destination_dataset=MY_BQ_DATASET\n",
    ")\n",
    "\n",
    "end = time.time()\n",
    "print(f\"elapsed time: {end - start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734c17ee",
   "metadata": {},
   "source": [
    "Load the data into a dataframe and preview a few rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e1b5f0",
   "metadata": {},
   "source": [
    "### Load the Processed GDELT Event Records to the BigQuery Destination Tables\n",
    "First load the data into a pandas dataframe and preview the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ffe34970-7d5c-4356-b8c7-1ab3e833ee6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>url</th>\n",
       "      <th>brand</th>\n",
       "      <th>description</th>\n",
       "      <th>article_count</th>\n",
       "      <th>articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>techcrunch.com</td>\n",
       "      <td>https://techcrunch.com</td>\n",
       "      <td>techcrunch</td>\n",
       "      <td>TechCrunch | Reporting on the business of tech...</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           domain                     url       brand  \\\n",
       "0  techcrunch.com  https://techcrunch.com  techcrunch   \n",
       "\n",
       "                                         description  article_count articles  \n",
       "0  TechCrunch | Reporting on the business of tech...              0       []  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geg_articles_full_source_df = pd.DataFrame(gdelt_data_processor.full_source_data)\n",
    "\n",
    "print(geg_articles_full_source_df.shape)\n",
    "geg_articles_full_source_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f173fdb9",
   "metadata": {},
   "source": [
    "Next we'll do a bit of transformation before loading into BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "429c9375-95e5-41df-aa5d-2b6b43380068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>url</th>\n",
       "      <th>language</th>\n",
       "      <th>date</th>\n",
       "      <th>Actor1Name</th>\n",
       "      <th>Actor2Name</th>\n",
       "      <th>GoldsteinScale</th>\n",
       "      <th>NumSources</th>\n",
       "      <th>NumArticles</th>\n",
       "      <th>AvgTone</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Malia Chung</td>\n",
       "      <td>Cookies Policy\\n\\nWhat Are Cookies\\n\\nAs is co...</td>\n",
       "      <td>Analytical / Navigation Cookies: These cookies...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://cyprus-mail.com/author/malia/</td>\n",
       "      <td>en</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://cyprus-mail.com/author/malia/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         title                                               text  \\\n",
       "0  Malia Chung  Cookies Policy\\n\\nWhat Are Cookies\\n\\nAs is co...   \n",
       "\n",
       "                                             summary publish_date  \\\n",
       "0  Analytical / Navigation Cookies: These cookies...         None   \n",
       "\n",
       "                                     url language date Actor1Name Actor2Name  \\\n",
       "0  https://cyprus-mail.com/author/malia/       en                              \n",
       "\n",
       "  GoldsteinScale  NumSources  NumArticles  AvgTone  \\\n",
       "0                          0            0      0.0   \n",
       "\n",
       "                                  source  \n",
       "0  https://cyprus-mail.com/author/malia/  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geg_articles_full_source_df = geg_articles_full_source_df.loc[geg_articles_full_source_df['article_count'] != 0]\n",
    "geg_articles_article_list = geg_articles_full_source_df['articles']\n",
    "\n",
    "article_rows = []\n",
    "\n",
    "for entry in geg_articles_article_list:\n",
    "    for ent in entry:\n",
    "        article_rows.append(ent)\n",
    "\n",
    "if len(article_rows) > 0:\n",
    "    geg_articles_df = pd.DataFrame(article_rows)\n",
    "    geg_articles_df.drop(columns=['authors','NumMentions'], inplace=True) # TODO - fix\n",
    "    geg_articles_df['source']=geg_articles_df['url']\n",
    "else:\n",
    "    print(\"No new articles...\")\n",
    "    geg_articles_df = geg_articles_full_source_df.head(1)\n",
    "\n",
    "print(geg_articles_df.shape)\n",
    "geg_articles_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f089840d",
   "metadata": {},
   "source": [
    "Load the data to BigQuery destination tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b84bd793-7943-4651-acb3-269f504692d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoadJob<project=wortz-project-352116, location=US, id=e37fcbf7-827a-4d62-887c-19cbc572acb3>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job = bqclient.load_table_from_dataframe(\n",
    "    geg_articles_df\n",
    "    , SCRAPED_GDELT_TABLE_REF\n",
    ")\n",
    "\n",
    "job.result()  # Wait for the job to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d9602b2-ec96-4e85-b3ad-14d1b711419a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"scraped articles published between `2023-06-14` to `2023-06-14` mentioning 'google' from `gdelt-bq.gdeltv2.geg_gcnlapi`\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TABLE_DESCRIPTION = f\"scraped articles published between `{MIN_DATE}` to `{MAX_DATE}` mentioning '{ACTOR_NAME}' from `gdelt-bq.gdeltv2.geg_gcnlapi`\"\n",
    "TABLE_DESCRIPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "25accbc8-05af-4dd5-b3f5-83551809418a",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = bqclient.get_table(SCRAPED_GDELT_TABLE_REF)  # API request\n",
    "table.description = f'{TABLE_DESCRIPTION}' # \"testing updated table description\"\n",
    "table = bqclient.update_table(table, [\"description\"])  # API request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bac00f8",
   "metadata": {},
   "source": [
    "Confirm that the BigQuery table name is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc3e4ed4-8b96-4bfc-b970-83f2ed07ca11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"scraped articles published between `2023-06-14` to `2023-06-14` mentioning 'google' from `gdelt-bq.gdeltv2.geg_gcnlapi`\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm updated description \n",
    "table.description"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m108"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
